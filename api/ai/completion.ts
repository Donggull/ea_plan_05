// Vercel API ë¼ìš°íŠ¸ - AI ì™„ì„± ìš”ì²­ ì²˜ë¦¬
// í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ API í‚¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì„œë²„ì‚¬ì´ë“œì—ì„œ ì²˜ë¦¬

import type { VercelRequest, VercelResponse } from '@vercel/node'
import { createClient } from '@supabase/supabase-js'

// ğŸ”¥ Vercel Serverless Function ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
export const config = {
  maxDuration: 180, // 3ë¶„ (í° ë¬¸ì„œ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ì‹œê°„)
}

// Supabase Service Client ìƒì„± í•¨ìˆ˜ (ì‚¬ìš©ëŸ‰ ê¸°ë¡ìš©)
function createSupabaseServiceClient() {
  const supabaseUrl = process.env['SUPABASE_URL']
  const supabaseServiceKey = process.env['SUPABASE_SERVICE_ROLE_KEY']

  if (!supabaseUrl || !supabaseServiceKey) {
    console.warn('âš ï¸ Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API ì‚¬ìš©ëŸ‰ ê¸°ë¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.')
    return null
  }

  return createClient(supabaseUrl, supabaseServiceKey)
}

// userId ì¶”ì¶œ í•¨ìˆ˜ (Authorization í—¤ë”ì—ì„œ)
async function extractUserId(authHeader: string | undefined, supabase: any): Promise<string | null> {
  if (!authHeader || !authHeader.startsWith('Bearer ') || !supabase) {
    return null
  }

  try {
    const token = authHeader.substring(7)
    const { data: { user }, error } = await supabase.auth.getUser(token)

    if (error || !user) {
      console.warn('âš ï¸ ì¸ì¦ í† í° ê²€ì¦ ì‹¤íŒ¨:', error?.message)
      return null
    }

    return user.id
  } catch (error) {
    console.error('âŒ userId ì¶”ì¶œ ì˜¤ë¥˜:', error)
    return null
  }
}

// API ì‚¬ìš©ëŸ‰ ê¸°ë¡ í•¨ìˆ˜
async function recordApiUsage(
  userId: string,
  provider: string,
  model: string,
  inputTokens: number,
  outputTokens: number,
  cost: number
) {
  try {
    const supabase = createSupabaseServiceClient()
    if (!supabase) {
      console.warn('âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ. API ì‚¬ìš©ëŸ‰ ê¸°ë¡ ê±´ë„ˆëœ€.')
      return
    }

    const now = new Date()
    const date = now.toISOString().split('T')[0]
    const hour = now.getHours()

    const { error } = await supabase
      .from('user_api_usage')
      .insert({
        user_id: userId,
        api_provider: provider,
        date: date,
        hour: hour,
        model: model,
        request_count: 1,
        input_tokens: inputTokens,
        output_tokens: outputTokens,
        total_tokens: inputTokens + outputTokens,
        cost: cost,
        response_time_ms: 0, // ì‘ë‹µ ì‹œê°„ì€ ë³„ë„ë¡œ ì¸¡ì • ê°€ëŠ¥
        success: true,
        endpoint: '/api/ai/completion',
        created_at: now.toISOString()
      })

    if (error) {
      console.error('âŒ API ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì˜¤ë¥˜:', error)
    } else {
      console.log('âœ… API ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì„±ê³µ:', {
        userId,
        model,
        cost: cost.toFixed(6),
        tokens: inputTokens + outputTokens
      })
    }
  } catch (error) {
    console.error('âŒ API ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì¤‘ ì˜ˆì™¸:', error)
  }
}

interface CompletionRequest {
  provider: 'openai' | 'anthropic' | 'google'
  model: string
  prompt: string
  maxTokens?: number
  temperature?: number
  topP?: number
}

interface CompletionResponse {
  content: string
  usage: {
    inputTokens: number
    outputTokens: number
    totalTokens: number
  }
  cost: {
    inputCost: number
    outputCost: number
    totalCost: number
  }
  model: string
  finishReason: string
  responseTime: number
}

export default async function handler(
  req: VercelRequest,
  res: VercelResponse
) {
  // CORS í—¤ë” ì¶”ê°€
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')

  // OPTIONS ìš”ì²­ ì²˜ë¦¬
  if (req.method === 'OPTIONS') {
    return res.status(200).end()
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  try {
    console.log('ğŸš€ [Vercel API] AI ì™„ì„± ìš”ì²­ ìˆ˜ì‹ :', {
      timestamp: new Date().toISOString(),
      userAgent: req.headers['user-agent'],
      hasBody: !!req.body,
      contentType: req.headers['content-type'],
      bodySize: req.body ? JSON.stringify(req.body).length : 0,
      hasAuth: !!req.headers.authorization
    })

    // ğŸ”¥ userId ì¶”ì¶œ (API ì‚¬ìš©ëŸ‰ ê¸°ë¡ì„ ìœ„í•´)
    const supabase = createSupabaseServiceClient()
    const userId = await extractUserId(req.headers.authorization, supabase)

    const { provider, model, prompt, maxTokens, temperature, topP }: CompletionRequest = req.body

    console.log('ğŸ“ [Vercel API] ìš”ì²­ íŒŒë¼ë¯¸í„°:', {
      provider,
      model,
      promptLength: prompt?.length || 0,
      maxTokens,
      temperature
    })

    if (!provider || !model || !prompt) {
      console.error('âŒ [Vercel API] í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½:', { provider, model, hasPrompt: !!prompt })
      return res.status(400).json({ error: 'Missing required parameters' })
    }

    // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    const apiKeys = {
      openai: process.env['OPENAI_API_KEY'],
      anthropic: process.env['ANTHROPIC_API_KEY'],
      google: process.env['GOOGLE_AI_API_KEY']
    }

    console.log('ğŸ”‘ [Vercel API] í™˜ê²½ë³€ìˆ˜ ìƒíƒœ:', {
      hasOpenAI: !!apiKeys.openai,
      hasAnthropic: !!apiKeys.anthropic,
      hasGoogle: !!apiKeys.google,
      requestedProvider: provider
    })

    const apiKey = apiKeys[provider]
    if (!apiKey) {
      console.error(`âŒ [Vercel API] ${provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`)
      return res.status(500).json({
        error: `${provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`,
        provider,
        availableKeys: Object.keys(apiKeys).filter(key => apiKeys[key as keyof typeof apiKeys]),
        timestamp: new Date().toISOString()
      })
    }

    // API í‚¤ í˜•ì‹ ê¸°ë³¸ ê²€ì¦
    if (provider === 'anthropic' && !apiKey.startsWith('sk-ant-')) {
      console.error(`âŒ [Vercel API] ${provider} API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.`)
      return res.status(500).json({
        error: `${provider} API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.`,
        provider,
        timestamp: new Date().toISOString()
      })
    }

    if (provider === 'openai' && !apiKey.startsWith('sk-')) {
      console.error(`âŒ [Vercel API] ${provider} API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.`)
      return res.status(500).json({
        error: `${provider} API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.`,
        provider,
        timestamp: new Date().toISOString()
      })
    }

    console.log(`ğŸ¤– [Vercel API] AI ì™„ì„± ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: ${provider} ${model}`)

    let response: CompletionResponse

    switch (provider) {
      case 'anthropic':
        response = await handleAnthropicRequest(apiKey, model, prompt, maxTokens, temperature, topP)
        break
      case 'openai':
        response = await handleOpenAIRequest(apiKey, model, prompt, maxTokens, temperature, topP)
        break
      case 'google':
        response = await handleGoogleAIRequest(apiKey, model, prompt, maxTokens, temperature, topP)
        break
      default:
        return res.status(400).json({ error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: ${provider}` })
    }

    console.log(`âœ… [Vercel API] AI ì‘ë‹µ ì™„ë£Œ: ${response.usage.totalTokens} í† í°, $${response.cost.totalCost.toFixed(4)}`)

    // ğŸ”¥ API ì‚¬ìš©ëŸ‰ ê¸°ë¡ (userIdê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    if (userId) {
      await recordApiUsage(
        userId,
        provider,
        model,
        response.usage.inputTokens,
        response.usage.outputTokens,
        response.cost.totalCost
      )
    } else {
      console.warn('âš ï¸ userIdê°€ ì—†ì–´ API ì‚¬ìš©ëŸ‰ì„ ê¸°ë¡í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Authorization í—¤ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.')
    }

    return res.status(200).json(response)

  } catch (error) {
    console.error('âŒ [Vercel API] AI ì™„ì„± ì²˜ë¦¬ ì˜¤ë¥˜ ìƒì„¸:', {
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      provider: req.body?.provider,
      model: req.body?.model,
      promptLength: req.body?.prompt?.length || 0,
      maxTokens: req.body?.maxTokens,
      temperature: req.body?.temperature,
      timestamp: new Date().toISOString()
    })

    // ë” ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì œê³µ
    let errorMessage = 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    let errorDetails = error instanceof Error ? error.message : String(error)

    // êµ¬ì²´ì ì¸ ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ë©”ì‹œì§€
    if (error instanceof Error) {
      if (error.message.includes('API í‚¤')) {
        errorMessage = 'AI API ì¸ì¦ ì˜¤ë¥˜'
        errorDetails = `${req.body?.provider || 'unknown'} AI ì„œë¹„ìŠ¤ì˜ API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`
      } else if (error.message.includes('timeout')) {
        errorMessage = 'AI API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼'
        errorDetails = 'AI ì„œë¹„ìŠ¤ ì‘ë‹µì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      } else if (error.message.includes('API ì˜¤ë¥˜')) {
        errorMessage = 'AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜'
        errorDetails = `${req.body?.provider || 'unknown'} AI ì„œë¹„ìŠ¤ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`
      }
    }

    return res.status(500).json({
      error: errorMessage,
      details: errorDetails,
      provider: req.body?.provider,
      model: req.body?.model,
      timestamp: new Date().toISOString(),
      // ë””ë²„ê¹…ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´ (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
      ...(process.env['NODE_ENV'] === 'development' && {
        debugInfo: {
          stack: error instanceof Error ? error.stack : undefined,
          requestBody: req.body
        }
      })
    })
  }
}

async function handleAnthropicRequest(
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 2000,
  temperature = 0.7
): Promise<CompletionResponse> {
  const startTime = Date.now()

  const controller = new AbortController()
  const timeoutId = setTimeout(() => controller.abort(), 120000) // 120ì´ˆ timeout (í° ë¬¸ì„œ ì²˜ë¦¬)

  try {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': apiKey,
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model,
        max_tokens: maxTokens,
        temperature,
        // top_p ì œê±°: Claude Sonnet 4.5ëŠ” temperatureì™€ top_p ë™ì‹œ ì‚¬ìš© ë¶ˆê°€
        messages: [{ role: 'user', content: prompt }]
      }),
      signal: controller.signal
    })

    clearTimeout(timeoutId)

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`âŒ [Anthropic API] ì˜¤ë¥˜ ì‘ë‹µ:`, {
        status: response.status,
        statusText: response.statusText,
        errorBody: errorText,
        model,
        promptLength: prompt.length
      })
      throw new Error(`Anthropic API ${response.status} ì˜¤ë¥˜: ${errorText}`)
    }

    const data = await response.json()
    const responseTime = Date.now() - startTime

    // ğŸ”¥ Anthropic API ì‘ë‹µ êµ¬ì¡° ê²€ì¦
    if (!data.content || !Array.isArray(data.content) || data.content.length === 0) {
      console.error('âŒ [Anthropic API] ì˜ëª»ëœ ì‘ë‹µ êµ¬ì¡°:', data)
      throw new Error('Anthropic API ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    }

    if (!data.content[0].text) {
      console.error('âŒ [Anthropic API] ì‘ë‹µ í…ìŠ¤íŠ¸ ì—†ìŒ:', data.content[0])
      throw new Error('Anthropic API ì‘ë‹µì— í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.')
    }

    // ğŸ”¥ ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ìš°ì„  ì‚¬ìš© (API ì‘ë‹µì— ìˆìœ¼ë©´)
    const inputTokens = data.usage?.input_tokens || estimateTokens(prompt, 'anthropic')
    const outputTokens = data.usage?.output_tokens || estimateTokens(data.content[0].text, 'anthropic')

    console.log('ğŸ“Š [Anthropic] í† í° ì‚¬ìš©ëŸ‰:', {
      inputTokens,
      outputTokens,
      totalTokens: inputTokens + outputTokens,
      source: data.usage ? 'API' : 'estimated'
    })

    // ëª¨ë¸ë³„ ë¹„ìš© ê³„ì‚°
    const pricing = getAnthropicPricing(model)
    const inputCost = (inputTokens * pricing.inputCost) / 1000000
    const outputCost = (outputTokens * pricing.outputCost) / 1000000

    return {
      content: data.content[0].text,
      usage: {
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens
      },
      cost: {
        inputCost,
        outputCost,
        totalCost: inputCost + outputCost
      },
      model,
      finishReason: data.stop_reason || 'stop',
      responseTime
    }
  } catch (error: any) {
    clearTimeout(timeoutId)
    console.error('âŒ [Anthropic] ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:', {
      errorName: error.name,
      errorMessage: error.message,
      errorStack: error.stack,
      model,
      promptLength: prompt.length,
      timestamp: new Date().toISOString()
    })

    if (error.name === 'AbortError') {
      throw new Error(`Anthropic API timeout after 120 seconds`)
    }
    throw error
  }
}

async function handleOpenAIRequest(
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 2000,
  temperature = 0.7,
  topP = 1
): Promise<CompletionResponse> {
  const startTime = Date.now()

  const controller = new AbortController()
  const timeoutId = setTimeout(() => controller.abort(), 120000) // 120ì´ˆ timeout (í° ë¬¸ì„œ ì²˜ë¦¬)

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        messages: [{ role: 'user', content: prompt }],
        max_tokens: maxTokens,
        temperature,
        top_p: topP
      }),
      signal: controller.signal
    })

    clearTimeout(timeoutId)

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`âŒ [OpenAI API] ì˜¤ë¥˜ ì‘ë‹µ:`, {
        status: response.status,
        statusText: response.statusText,
        errorBody: errorText,
        model,
        promptLength: prompt.length
      })
      throw new Error(`OpenAI API ${response.status} ì˜¤ë¥˜: ${errorText}`)
    }

    const data = await response.json()
    const responseTime = Date.now() - startTime

    const pricing = getOpenAIPricing(model)
    const inputCost = (data.usage.prompt_tokens * pricing.inputCost) / 1000000
    const outputCost = (data.usage.completion_tokens * pricing.outputCost) / 1000000

    return {
      content: data.choices[0].message.content,
      usage: {
        inputTokens: data.usage.prompt_tokens,
        outputTokens: data.usage.completion_tokens,
        totalTokens: data.usage.total_tokens
      },
      cost: {
        inputCost,
        outputCost,
        totalCost: inputCost + outputCost
      },
      model,
      finishReason: data.choices[0].finish_reason,
      responseTime
    }
  } catch (error: any) {
    clearTimeout(timeoutId)
    console.error('âŒ [OpenAI] ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:', {
      errorName: error.name,
      errorMessage: error.message,
      errorStack: error.stack,
      model,
      promptLength: prompt.length,
      timestamp: new Date().toISOString()
    })

    if (error.name === 'AbortError') {
      throw new Error(`OpenAI API timeout after 120 seconds`)
    }
    throw error
  }
}

async function handleGoogleAIRequest(
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 2000,
  temperature = 0.7,
  topP = 1
): Promise<CompletionResponse> {
  const startTime = Date.now()

  const controller = new AbortController()
  const timeoutId = setTimeout(() => controller.abort(), 120000) // 120ì´ˆ timeout (í° ë¬¸ì„œ ì²˜ë¦¬)

  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1/models/${model}:generateContent?key=${apiKey}`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          contents: [{ parts: [{ text: prompt }] }],
          generationConfig: {
            maxOutputTokens: maxTokens,
            temperature,
            topP
          }
        }),
        signal: controller.signal
      }
    )

    clearTimeout(timeoutId)

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`âŒ [Google AI API] ì˜¤ë¥˜ ì‘ë‹µ:`, {
        status: response.status,
        statusText: response.statusText,
        errorBody: errorText,
        model,
        promptLength: prompt.length
      })
      throw new Error(`Google AI API ${response.status} ì˜¤ë¥˜: ${errorText}`)
    }

    const data = await response.json()
    const responseTime = Date.now() - startTime

    const inputTokens = estimateTokens(prompt, 'google')
    const outputTokens = estimateTokens(data.candidates[0].content.parts[0].text, 'google')

    const pricing = getGoogleAIPricing(model)
    const inputCost = (inputTokens * pricing.inputCost) / 1000000
    const outputCost = (outputTokens * pricing.outputCost) / 1000000

    return {
      content: data.candidates[0].content.parts[0].text,
      usage: {
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens
      },
      cost: {
        inputCost,
        outputCost,
        totalCost: inputCost + outputCost
      },
      model,
      finishReason: data.candidates[0].finishReason?.toLowerCase() || 'stop',
      responseTime
    }
  } catch (error: any) {
    clearTimeout(timeoutId)
    console.error('âŒ [Google AI] ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:', {
      errorName: error.name,
      errorMessage: error.message,
      errorStack: error.stack,
      model,
      promptLength: prompt.length,
      timestamp: new Date().toISOString()
    })

    if (error.name === 'AbortError') {
      throw new Error(`Google AI API timeout after 120 seconds`)
    }
    throw error
  }
}

// í† í° ì¶”ì • í•¨ìˆ˜
function estimateTokens(text: string, provider: string): number {
  const length = text.length
  switch (provider) {
    case 'anthropic':
      return Math.ceil(length / 3.5) // Claude: 1í† í° â‰ˆ 3.5ê¸€ì
    case 'openai':
      return Math.ceil(length / 4) // GPT: 1í† í° â‰ˆ 4ê¸€ì
    case 'google':
      return Math.ceil(length / 4) // Gemini: 1í† í° â‰ˆ 4ê¸€ì
    default:
      return Math.ceil(length / 4)
  }
}

// ê°€ê²© ì •ë³´ í•¨ìˆ˜ë“¤
function getAnthropicPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'claude-sonnet-4-5-20250929': { inputCost: 3, outputCost: 15 },
    'claude-3-5-sonnet-20241022': { inputCost: 3, outputCost: 15 },
    'claude-3-5-haiku-20241022': { inputCost: 0.8, outputCost: 4 },
    'claude-3-opus-20240229': { inputCost: 15, outputCost: 75 },
    'claude-3-haiku-20240307': { inputCost: 0.25, outputCost: 1.25 }
  }
  return pricing[model] || { inputCost: 3, outputCost: 15 }
}

function getOpenAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gpt-4o': { inputCost: 5, outputCost: 15 },
    'gpt-4o-mini': { inputCost: 0.15, outputCost: 0.6 },
    'gpt-4-turbo': { inputCost: 10, outputCost: 30 },
    'gpt-3.5-turbo': { inputCost: 0.5, outputCost: 1.5 }
  }
  return pricing[model] || { inputCost: 5, outputCost: 15 }
}

function getGoogleAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gemini-2.0-flash-exp': { inputCost: 0.075, outputCost: 0.3 },
    'gemini-1.5-pro': { inputCost: 1.25, outputCost: 5 },
    'gemini-1.5-flash': { inputCost: 0.075, outputCost: 0.3 }
  }
  return pricing[model] || { inputCost: 1.25, outputCost: 5 }
}