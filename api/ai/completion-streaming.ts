// Vercel API ë¼ìš°íŠ¸ - AI ìŠ¤íŠ¸ë¦¬ë° ì™„ì„± ìš”ì²­ ì²˜ë¦¬ (ë³´ê³ ì„œ ìƒì„± ì „ìš©)
// ì¼ë°˜ completion.tsëŠ” ì§ˆë¬¸ ìƒì„±ìš©ìœ¼ë¡œ ìœ ì§€í•˜ê³ , ì´ íŒŒì¼ì€ ë³´ê³ ì„œ ìƒì„± ì „ìš© ìŠ¤íŠ¸ë¦¬ë° API

import type { VercelRequest, VercelResponse } from '@vercel/node'

interface CompletionStreamRequest {
  provider: 'openai' | 'anthropic' | 'google'
  model: string
  prompt: string
  maxTokens?: number
  temperature?: number
  topP?: number
}

// Vercel ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ ì„¤ì •
// ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì€ ì²« ì‘ë‹µë§Œ 60ì´ˆ ì•ˆì— ì‹œì‘í•˜ë©´ ì´í›„ ë¬´ì œí•œ
export const config = {
  maxDuration: 60, // Pro í”Œëœ ìµœëŒ€ê°’ (ì²« ì‘ë‹µë§Œ ë¹ ë¥´ê²Œ ì‹œì‘í•˜ë©´ ë¨)
}

export default async function handler(
  req: VercelRequest,
  res: VercelResponse
) {
  // CORS í—¤ë” ì¶”ê°€
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')

  // OPTIONS ìš”ì²­ ì²˜ë¦¬
  if (req.method === 'OPTIONS') {
    return res.status(200).end()
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  try {
    console.log('ğŸŒŠ [Streaming API] ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ìˆ˜ì‹ :', {
      timestamp: new Date().toISOString(),
      userAgent: req.headers['user-agent'],
    })

    const { provider, model, prompt, maxTokens, temperature, topP }: CompletionStreamRequest = req.body

    console.log('ğŸ“ [Streaming API] ìš”ì²­ íŒŒë¼ë¯¸í„°:', {
      provider,
      model,
      promptLength: prompt?.length || 0,
      maxTokens,
      temperature
    })

    if (!provider || !model || !prompt) {
      console.error('âŒ [Streaming API] í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½:', { provider, model, hasPrompt: !!prompt })
      return res.status(400).json({ error: 'Missing required parameters' })
    }

    // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    const apiKeys = {
      openai: process.env['OPENAI_API_KEY'],
      anthropic: process.env['ANTHROPIC_API_KEY'],
      google: process.env['GOOGLE_AI_API_KEY']
    }

    const apiKey = apiKeys[provider]
    if (!apiKey) {
      console.error(`âŒ [Streaming API] ${provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`)
      return res.status(500).json({
        error: `${provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`,
        provider,
      })
    }

    // âœ… SSE (Server-Sent Events) í—¤ë” ì„¤ì •
    res.setHeader('Content-Type', 'text/event-stream')
    res.setHeader('Cache-Control', 'no-cache, no-transform')
    res.setHeader('Connection', 'keep-alive')
    res.setHeader('X-Accel-Buffering', 'no') // Nginx ë²„í¼ë§ ë°©ì§€

    console.log(`ğŸš€ [Streaming API] ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: ${provider} ${model}`)

    // Providerë³„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    switch (provider) {
      case 'anthropic':
        await handleAnthropicStreaming(res, apiKey, model, prompt, maxTokens, temperature, topP)
        return // âœ… TypeScript ì˜¤ë¥˜ ìˆ˜ì •: ëª¨ë“  ê²½ë¡œì—ì„œ return
      case 'openai':
        await handleOpenAIStreaming(res, apiKey, model, prompt, maxTokens, temperature, topP)
        return // âœ… TypeScript ì˜¤ë¥˜ ìˆ˜ì •: ëª¨ë“  ê²½ë¡œì—ì„œ return
      case 'google':
        await handleGoogleAIStreaming(res, apiKey, model, prompt, maxTokens, temperature, topP)
        return // âœ… TypeScript ì˜¤ë¥˜ ìˆ˜ì •: ëª¨ë“  ê²½ë¡œì—ì„œ return
      default:
        res.write(`data: ${JSON.stringify({ type: 'error', error: `ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: ${provider}` })}\n\n`)
        res.end()
        return
    }

  } catch (error) {
    console.error('âŒ [Streaming API] ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:', {
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
    })

    // ìŠ¤íŠ¸ë¦¬ë° ë„ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ
    try {
      res.write(`data: ${JSON.stringify({
        type: 'error',
        error: error instanceof Error ? error.message : 'ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
      })}\n\n`)
      res.end()
    } catch (writeError) {
      // ì´ë¯¸ ì¢…ë£Œëœ ì—°ê²°ì¼ ìˆ˜ ìˆìŒ
      console.error('ì‘ë‹µ ì“°ê¸° ì‹¤íŒ¨:', writeError)
    }
  }
}

// Anthropic ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
async function handleAnthropicStreaming(
  res: VercelResponse,
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 3000,
  temperature = 0.3,
  topP = 1
) {
  const startTime = Date.now()

  console.log('ğŸ¤– [Anthropic Stream] ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ì‹œì‘')

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'Content-Type': 'application/json',
      'anthropic-version': '2023-06-01'
    },
    body: JSON.stringify({
      model,
      max_tokens: maxTokens,
      temperature,
      top_p: topP,
      messages: [{ role: 'user', content: prompt }],
      stream: true, // ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    })
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`Anthropic API ì˜¤ë¥˜: ${response.status} - ${errorText}`)
  }

  if (!response.body) {
    throw new Error('ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.')
  }

  const reader = response.body.getReader()
  const decoder = new TextDecoder()

  let fullContent = ''
  let inputTokens = 0
  let outputTokens = 0
  let buffer = ''
  let stopEventReceived = false  // ğŸ”¥ message_stop í”Œë˜ê·¸

  console.log('ğŸ“¥ [Anthropic Stream] ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  ì‹œì‘')

  try {
    while (true) {
      const { done, value } = await reader.read()

      if (done) {
        console.log('âœ… [Anthropic Stream] ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ, ë‚¨ì€ ë²„í¼ ì²˜ë¦¬ ì¤‘...')
        // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹œ ë²„í¼ì— ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if (buffer.trim()) {
          console.log('ğŸ“¦ [Anthropic Stream] ë‚¨ì€ ë²„í¼:', buffer.substring(0, 200))
          const remainingLines = buffer.split('\n')

          for (const line of remainingLines) {
            if (line.trim() && line.startsWith('data:')) {
              const data = line.slice(5).trim()
              if (data && data !== '[DONE]') {
                try {
                  const event = JSON.parse(data)

                  if (event.type === 'content_block_delta' && event.delta?.text) {
                    fullContent += event.delta.text
                  }
                  if (event.type === 'message_delta' && event.usage) {
                    outputTokens = event.usage.output_tokens || 0
                  }
                } catch (parseError) {
                  console.warn('âš ï¸ ë‚¨ì€ ë²„í¼ íŒŒì‹± ì˜¤ë¥˜:', data.substring(0, 100))
                }
              }
            }
          }
        }
        break
      }

      // SSE ë°ì´í„° íŒŒì‹±
      buffer += decoder.decode(value, { stream: true })
      const lines = buffer.split('\n')

      // ë§ˆì§€ë§‰ ë¶ˆì™„ì „í•œ ë¼ì¸ì€ ë‹¤ìŒ ì²­í¬ë¡œ
      buffer = lines.pop() || ''

      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = line.slice(5).trim()

          if (data === '[DONE]') continue

          try {
            const event = JSON.parse(data)

            // content_block_delta: í…ìŠ¤íŠ¸ ì¡°ê°
            if (event.type === 'content_block_delta' && event.delta?.text) {
              fullContent += event.delta.text

              // í´ë¼ì´ì–¸íŠ¸ë¡œ ì¦‰ì‹œ ì „ì†¡
              res.write(`data: ${JSON.stringify({
                type: 'text',
                content: event.delta.text,
                fullContent: fullContent
              })}\n\n`)
            }

            // message_delta: í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
            if (event.type === 'message_delta' && event.usage) {
              outputTokens = event.usage.output_tokens || 0
            }

            // message_start: ì…ë ¥ í† í° ì •ë³´
            if (event.type === 'message_start' && event.message?.usage) {
              inputTokens = event.message.usage.input_tokens || 0
            }

            // ğŸ”¥ message_stop: Anthropic ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œê·¸ë„
            if (event.type === 'message_stop') {
              console.log('ğŸ›‘ [Anthropic Stream] message_stop ì´ë²¤íŠ¸ ìˆ˜ì‹ ! done ì´ë²¤íŠ¸ ì „ì†¡')
              stopEventReceived = true

              const responseTime = Date.now() - startTime
              const pricing = getAnthropicPricing(model)
              const inputCost = (inputTokens * pricing.inputCost) / 1000000
              const outputCost = (outputTokens * pricing.outputCost) / 1000000

              const doneEvent = JSON.stringify({
                type: 'done',
                content: fullContent,
                usage: {
                  inputTokens,
                  outputTokens,
                  totalTokens: inputTokens + outputTokens
                },
                cost: {
                  inputCost,
                  outputCost,
                  totalCost: inputCost + outputCost
                },
                model,
                finishReason: 'stop',
                responseTime
              })

              console.log('ğŸ“¤ [Anthropic Stream] done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

              // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
              for (let i = 0; i < 10; i++) {
                res.write(`data: ${doneEvent}\n\n`)
              }

              // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
              for (let i = 0; i < 5; i++) {
                res.write(`: keepalive\n\n`)
              }

              // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)

              console.log(`âœ… [Anthropic Stream] done ì´ë²¤íŠ¸ ì „ì†¡ ì™„ë£Œ: ${inputTokens + outputTokens} í† í°, ${responseTime}ms`)

              // âœ… reader.cancel() ì œê±° - ìŠ¤íŠ¸ë¦¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë˜ë„ë¡ í•¨
              // âœ… res.end() ì œê±° - ë£¨í”„ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
              // âœ… return ì œê±° - ë£¨í”„ ê³„ì† (ê³§ done: trueë¥¼ ë°›ìŒ)
            }

          } catch (parseError) {
            console.warn('âš ï¸ SSE íŒŒì‹± ì˜¤ë¥˜:', data)
          }
        }
      }
    }

    // ğŸ”¥ message_stop ì´ë²¤íŠ¸ë¥¼ ë°›ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ fallback done ì´ë²¤íŠ¸ ì „ì†¡
    if (!stopEventReceived) {
      console.log('âš ï¸ [Anthropic Stream] message_stop ë¯¸ìˆ˜ì‹ ! fallback done ì´ë²¤íŠ¸ ì „ì†¡')

      const responseTime = Date.now() - startTime
      const pricing = getAnthropicPricing(model)
      const inputCost = (inputTokens * pricing.inputCost) / 1000000
      const outputCost = (outputTokens * pricing.outputCost) / 1000000

      const doneEvent = JSON.stringify({
        type: 'done',
        content: fullContent,
        usage: {
          inputTokens,
          outputTokens,
          totalTokens: inputTokens + outputTokens
        },
        cost: {
          inputCost,
          outputCost,
          totalCost: inputCost + outputCost
        },
        model,
        finishReason: 'stop',
        responseTime
      })

      console.log('ğŸ“¤ [Anthropic Stream] fallback done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

      // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
      for (let i = 0; i < 10; i++) {
        res.write(`data: ${doneEvent}\n\n`)
      }

      // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
      for (let i = 0; i < 5; i++) {
        res.write(`: keepalive\n\n`)
      }

      // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
    }

    // ğŸ”¥ ë²„í¼ í”ŒëŸ¬ì‹œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì§€ì—° (Vercel í™˜ê²½ì—ì„œ ì•ˆì •ì )
    await new Promise(resolve => setTimeout(resolve, 1000))

    console.log(`âœ… [Anthropic Stream] ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì™„ë£Œ`)
    res.end()

  } catch (error) {
    console.error('âŒ [Anthropic Stream] ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜:', error)
    throw error
  }
}

// OpenAI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
async function handleOpenAIStreaming(
  res: VercelResponse,
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 3000,
  temperature = 0.3,
  topP = 1
) {
  const startTime = Date.now()

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model,
      messages: [{ role: 'user', content: prompt }],
      max_tokens: maxTokens,
      temperature,
      top_p: topP,
      stream: true,
    })
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`OpenAI API ì˜¤ë¥˜: ${response.status} - ${errorText}`)
  }

  if (!response.body) {
    throw new Error('ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.')
  }

  const reader = response.body.getReader()
  const decoder = new TextDecoder()

  let fullContent = ''
  let inputTokens = 0
  let outputTokens = 0
  let buffer = ''
  let stopEventReceived = false  // ğŸ”¥ finish_reason í”Œë˜ê·¸

  try {
    while (true) {
      const { done, value } = await reader.read()

      if (done) {
        console.log('âœ… [OpenAI Stream] ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ, ë‚¨ì€ ë²„í¼ ì²˜ë¦¬ ì¤‘...')
        // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹œ ë²„í¼ì— ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if (buffer.trim()) {
          console.log('ğŸ“¦ [OpenAI Stream] ë‚¨ì€ ë²„í¼:', buffer.substring(0, 200))
          const remainingLines = buffer.split('\n')

          for (const line of remainingLines) {
            if (line.trim() && line.startsWith('data:')) {
              const data = line.slice(5).trim()
              if (data && data !== '[DONE]') {
                try {
                  const event = JSON.parse(data)
                  const content = event.choices?.[0]?.delta?.content

                  if (content) {
                    fullContent += content
                  }
                  if (event.usage) {
                    inputTokens = event.usage.prompt_tokens
                    outputTokens = event.usage.completion_tokens
                  }
                } catch (parseError) {
                  console.warn('âš ï¸ ë‚¨ì€ ë²„í¼ íŒŒì‹± ì˜¤ë¥˜:', data.substring(0, 100))
                }
              }
            }
          }
        }
        break
      }

      buffer += decoder.decode(value, { stream: true })
      const lines = buffer.split('\n')
      buffer = lines.pop() || ''

      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = line.slice(5).trim()

          if (data === '[DONE]') continue

          try {
            const event = JSON.parse(data)
            const content = event.choices?.[0]?.delta?.content
            const finishReason = event.choices?.[0]?.finish_reason

            if (content) {
              fullContent += content

              res.write(`data: ${JSON.stringify({
                type: 'text',
                content,
                fullContent
              })}\n\n`)
            }

            // OpenAIëŠ” ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶”ì •
            if (event.usage) {
              inputTokens = event.usage.prompt_tokens
              outputTokens = event.usage.completion_tokens
            }

            // ğŸ”¥ finish_reason: OpenAI ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œê·¸ë„
            if (finishReason) {
              console.log(`ğŸ›‘ [OpenAI Stream] finish_reason ìˆ˜ì‹ : ${finishReason}! done ì´ë²¤íŠ¸ ì „ì†¡`)
              stopEventReceived = true

              // í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì •
              if (!inputTokens) inputTokens = estimateTokens(prompt, 'openai')
              if (!outputTokens) outputTokens = estimateTokens(fullContent, 'openai')

              const responseTime = Date.now() - startTime
              const pricing = getOpenAIPricing(model)
              const inputCost = (inputTokens * pricing.inputCost) / 1000000
              const outputCost = (outputTokens * pricing.outputCost) / 1000000

              const doneEvent = JSON.stringify({
                type: 'done',
                content: fullContent,
                usage: { inputTokens, outputTokens, totalTokens: inputTokens + outputTokens },
                cost: { inputCost, outputCost, totalCost: inputCost + outputCost },
                model,
                finishReason,
                responseTime
              })

              console.log('ğŸ“¤ [OpenAI Stream] done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

              // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
              for (let i = 0; i < 10; i++) {
                res.write(`data: ${doneEvent}\n\n`)
              }

              // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
              for (let i = 0; i < 5; i++) {
                res.write(`: keepalive\n\n`)
              }

              // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)

              console.log(`âœ… [OpenAI Stream] done ì´ë²¤íŠ¸ ì „ì†¡ ì™„ë£Œ: ${inputTokens + outputTokens} í† í°, ${responseTime}ms`)

              // âœ… reader.cancel() ì œê±° - ìŠ¤íŠ¸ë¦¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë˜ë„ë¡ í•¨
              // âœ… res.end() ì œê±° - ë£¨í”„ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
              // âœ… return ì œê±° - ë£¨í”„ ê³„ì† (ê³§ done: trueë¥¼ ë°›ìŒ)
            }

          } catch (parseError) {
            console.warn('âš ï¸ SSE íŒŒì‹± ì˜¤ë¥˜:', data)
          }
        }
      }
    }

    // ğŸ”¥ finish_reasonì„ ë°›ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ fallback done ì´ë²¤íŠ¸ ì „ì†¡
    if (!stopEventReceived) {
      console.log('âš ï¸ [OpenAI Stream] finish_reason ë¯¸ìˆ˜ì‹ ! fallback done ì´ë²¤íŠ¸ ì „ì†¡')

      // í† í°ì´ ì—†ìœ¼ë©´ ì¶”ì •
      if (!inputTokens) inputTokens = estimateTokens(prompt, 'openai')
      if (!outputTokens) outputTokens = estimateTokens(fullContent, 'openai')

      const responseTime = Date.now() - startTime
      const pricing = getOpenAIPricing(model)
      const inputCost = (inputTokens * pricing.inputCost) / 1000000
      const outputCost = (outputTokens * pricing.outputCost) / 1000000

      const doneEvent = JSON.stringify({
        type: 'done',
        content: fullContent,
        usage: { inputTokens, outputTokens, totalTokens: inputTokens + outputTokens },
        cost: { inputCost, outputCost, totalCost: inputCost + outputCost },
        model,
        finishReason: 'stop',
        responseTime
      })

      console.log('ğŸ“¤ [OpenAI Stream] fallback done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

      // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
      for (let i = 0; i < 10; i++) {
        res.write(`data: ${doneEvent}\n\n`)
      }

      // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
      for (let i = 0; i < 5; i++) {
        res.write(`: keepalive\n\n`)
      }

      // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
    }

    // ğŸ”¥ ë²„í¼ í”ŒëŸ¬ì‹œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì§€ì—° (Vercel í™˜ê²½ì—ì„œ ì•ˆì •ì )
    await new Promise(resolve => setTimeout(resolve, 1000))

    console.log(`âœ… [OpenAI Stream] ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì™„ë£Œ`)
    res.end()

  } catch (error) {
    console.error('âŒ [OpenAI Stream] ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜:', error)
    throw error
  }
}

// Google AI ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
async function handleGoogleAIStreaming(
  res: VercelResponse,
  apiKey: string,
  model: string,
  prompt: string,
  maxTokens = 3000,
  temperature = 0.3,
  topP = 1
) {
  const startTime = Date.now()

  const response = await fetch(
    `https://generativelanguage.googleapis.com/v1/models/${model}:streamGenerateContent?key=${apiKey}&alt=sse`,
    {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{ parts: [{ text: prompt }] }],
        generationConfig: {
          maxOutputTokens: maxTokens,
          temperature,
          topP
        }
      })
    }
  )

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`Google AI API ì˜¤ë¥˜: ${response.status} - ${errorText}`)
  }

  if (!response.body) {
    throw new Error('ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.')
  }

  const reader = response.body.getReader()
  const decoder = new TextDecoder()

  let fullContent = ''
  let buffer = ''
  let stopEventReceived = false  // ğŸ”¥ finishReason í”Œë˜ê·¸

  try {
    while (true) {
      const { done, value } = await reader.read()

      if (done) {
        console.log('âœ… [Google AI Stream] ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ, ë‚¨ì€ ë²„í¼ ì²˜ë¦¬ ì¤‘...')
        // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì‹œ ë²„í¼ì— ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        if (buffer.trim()) {
          console.log('ğŸ“¦ [Google AI Stream] ë‚¨ì€ ë²„í¼:', buffer.substring(0, 200))
          const remainingLines = buffer.split('\n')

          for (const line of remainingLines) {
            if (line.trim() && line.startsWith('data:')) {
              const data = line.slice(5).trim()
              if (data) {
                try {
                  const event = JSON.parse(data)
                  const content = event.candidates?.[0]?.content?.parts?.[0]?.text

                  if (content) {
                    fullContent += content
                  }
                } catch (parseError) {
                  console.warn('âš ï¸ ë‚¨ì€ ë²„í¼ íŒŒì‹± ì˜¤ë¥˜:', data.substring(0, 100))
                }
              }
            }
          }
        }
        break
      }

      buffer += decoder.decode(value, { stream: true })
      const lines = buffer.split('\n')
      buffer = lines.pop() || ''

      for (const line of lines) {
        if (line.startsWith('data:')) {
          const data = line.slice(5).trim()

          try {
            const event = JSON.parse(data)
            const content = event.candidates?.[0]?.content?.parts?.[0]?.text
            const finishReason = event.candidates?.[0]?.finishReason

            if (content) {
              fullContent += content

              res.write(`data: ${JSON.stringify({
                type: 'text',
                content,
                fullContent
              })}\n\n`)
            }

            // ğŸ”¥ finishReason: Google AI ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì‹œê·¸ë„
            if (finishReason) {
              console.log(`ğŸ›‘ [Google AI Stream] finishReason ìˆ˜ì‹ : ${finishReason}! done ì´ë²¤íŠ¸ ì „ì†¡`)
              stopEventReceived = true

              const inputTokens = estimateTokens(prompt, 'google')
              const outputTokens = estimateTokens(fullContent, 'google')
              const responseTime = Date.now() - startTime
              const pricing = getGoogleAIPricing(model)
              const inputCost = (inputTokens * pricing.inputCost) / 1000000
              const outputCost = (outputTokens * pricing.outputCost) / 1000000

              const doneEvent = JSON.stringify({
                type: 'done',
                content: fullContent,
                usage: { inputTokens, outputTokens, totalTokens: inputTokens + outputTokens },
                cost: { inputCost, outputCost, totalCost: inputCost + outputCost },
                model,
                finishReason,
                responseTime
              })

              console.log('ğŸ“¤ [Google AI Stream] done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

              // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
              for (let i = 0; i < 10; i++) {
                res.write(`data: ${doneEvent}\n\n`)
              }

              // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
              for (let i = 0; i < 5; i++) {
                res.write(`: keepalive\n\n`)
              }

              // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)
              res.write(`data: [DONE]\n\n`)

              console.log(`âœ… [Google AI Stream] done ì´ë²¤íŠ¸ ì „ì†¡ ì™„ë£Œ: ${inputTokens + outputTokens} í† í°, ${responseTime}ms`)

              // âœ… reader.cancel() ì œê±° - ìŠ¤íŠ¸ë¦¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì¢…ë£Œë˜ë„ë¡ í•¨
              // âœ… res.end() ì œê±° - ë£¨í”„ê°€ ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
              // âœ… return ì œê±° - ë£¨í”„ ê³„ì† (ê³§ done: trueë¥¼ ë°›ìŒ)
            }

          } catch (parseError) {
            console.warn('âš ï¸ SSE íŒŒì‹± ì˜¤ë¥˜:', data)
          }
        }
      }
    }

    // ğŸ”¥ finishReasonì„ ë°›ì§€ ëª»í•œ ê²½ìš°ì—ë§Œ fallback done ì´ë²¤íŠ¸ ì „ì†¡
    if (!stopEventReceived) {
      console.log('âš ï¸ [Google AI Stream] finishReason ë¯¸ìˆ˜ì‹ ! fallback done ì´ë²¤íŠ¸ ì „ì†¡')

      const inputTokens = estimateTokens(prompt, 'google')
      const outputTokens = estimateTokens(fullContent, 'google')
      const responseTime = Date.now() - startTime
      const pricing = getGoogleAIPricing(model)
      const inputCost = (inputTokens * pricing.inputCost) / 1000000
      const outputCost = (outputTokens * pricing.outputCost) / 1000000

      const doneEvent = JSON.stringify({
        type: 'done',
        content: fullContent,
        usage: { inputTokens, outputTokens, totalTokens: inputTokens + outputTokens },
        cost: { inputCost, outputCost, totalCost: inputCost + outputCost },
        model,
        finishReason: 'stop',
        responseTime
      })

      console.log('ğŸ“¤ [Google AI Stream] fallback done ì´ë²¤íŠ¸ ì „ì†¡:', doneEvent.substring(0, 200))

      // ğŸ”¥ done ì´ë²¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë²ˆ ì „ì†¡í•˜ì—¬ í™•ì‹¤íˆ ì „ë‹¬ ë³´ì¥ (Vercel ë²„í¼ë§ ëŒ€ì‘)
      for (let i = 0; i < 10; i++) {
        res.write(`data: ${doneEvent}\n\n`)
      }

      // ğŸ”¥ SSE keepalive ì£¼ì„ìœ¼ë¡œ ë²„í¼ í”ŒëŸ¬ì‹œ ê°•ì œ
      for (let i = 0; i < 5; i++) {
        res.write(`: keepalive\n\n`)
      }

      // ğŸ”¥ SSE í‘œì¤€ ì¢…ë£Œ ë§ˆì»¤ ì „ì†¡
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
      res.write(`data: [DONE]\n\n`)
    }

    // ğŸ”¥ ë²„í¼ í”ŒëŸ¬ì‹œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì§€ì—° (Vercel í™˜ê²½ì—ì„œ ì•ˆì •ì )
    await new Promise(resolve => setTimeout(resolve, 1000))

    console.log(`âœ… [Google AI Stream] ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì™„ë£Œ`)
    res.end()

  } catch (error) {
    console.error('âŒ [Google AI Stream] ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜¤ë¥˜:', error)
    throw error
  }
}

// í† í° ì¶”ì • í•¨ìˆ˜
function estimateTokens(text: string, provider: string): number {
  const length = text.length
  switch (provider) {
    case 'anthropic':
      return Math.ceil(length / 3.5)
    case 'openai':
      return Math.ceil(length / 4)
    case 'google':
      return Math.ceil(length / 4)
    default:
      return Math.ceil(length / 4)
  }
}

// ê°€ê²© ì •ë³´ í•¨ìˆ˜ë“¤
function getAnthropicPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'claude-sonnet-4-20250514': { inputCost: 3, outputCost: 15 },
    'claude-3-5-sonnet-20241022': { inputCost: 3, outputCost: 15 },
    'claude-3-opus-20240229': { inputCost: 15, outputCost: 75 },
    'claude-3-haiku-20240307': { inputCost: 0.25, outputCost: 1.25 }
  }
  return pricing[model] || { inputCost: 3, outputCost: 15 }
}

function getOpenAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gpt-4o': { inputCost: 5, outputCost: 15 },
    'gpt-4o-mini': { inputCost: 0.15, outputCost: 0.6 },
    'gpt-4-turbo': { inputCost: 10, outputCost: 30 },
    'gpt-3.5-turbo': { inputCost: 0.5, outputCost: 1.5 }
  }
  return pricing[model] || { inputCost: 5, outputCost: 15 }
}

function getGoogleAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gemini-2.0-flash-exp': { inputCost: 0.075, outputCost: 0.3 },
    'gemini-1.5-pro': { inputCost: 1.25, outputCost: 5 },
    'gemini-1.5-flash': { inputCost: 0.075, outputCost: 0.3 }
  }
  return pricing[model] || { inputCost: 1.25, outputCost: 5 }
}
