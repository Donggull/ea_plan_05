// Vercel API ë¼ìš°íŠ¸ - AI ì§ˆë¬¸ ìƒì„± ì „ìš© ì—”ë“œí¬ì¸íŠ¸
// ì‚¬ì „ ë¶„ì„ ë‹¨ê³„ì—ì„œ ë¬¸ì„œ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±ì— íŠ¹í™”

import type { VercelRequest, VercelResponse } from '@vercel/node'
import { createClient } from '@supabase/supabase-js'

interface QuestionRequest {
  provider: 'openai' | 'anthropic' | 'google'
  model: string
  projectId: string
  projectInfo: {
    name?: string
    description?: string
    industry?: string
  }
  documents: Array<{
    name: string
    summary?: string
    content?: string
  }>
  preAnalysisData?: {
    hasPreAnalysis: boolean
    report: any | null
    documentAnalyses: any[]
    summary: string
  }
  context?: {
    userId?: string
    sessionId?: string
    requestType?: string
  }
}

interface GeneratedQuestion {
  category: string
  text: string
  type: 'text' | 'select' | 'multiselect' | 'number' | 'textarea'
  options?: string[]
  required: boolean
  helpText?: string
  priority: 'high' | 'medium' | 'low'
  confidence: number
}

interface QuestionResponse {
  questions: GeneratedQuestion[]
  usage: {
    inputTokens: number
    outputTokens: number
    totalTokens: number
  }
  cost: {
    inputCost: number
    outputCost: number
    totalCost: number
  }
  model: string
  responseTime: number
  metadata: {
    projectId: string
    totalQuestions: number
    categories: string[]
  }
}

// Supabase server client ìƒì„± í•¨ìˆ˜
function createServerSupabaseClient(authToken?: string) {
  const supabaseUrl = process.env.SUPABASE_URL
  const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY

  if (!supabaseUrl || !supabaseServiceKey) {
    throw new Error('Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  const supabase = createClient(supabaseUrl, supabaseServiceKey)

  // ì¸ì¦ í† í°ì´ ìˆìœ¼ë©´ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
  if (authToken) {
    supabase.auth.setSession({
      access_token: authToken,
      refresh_token: '',
      expires_in: 3600,
      token_type: 'bearer',
      user: null as any
    } as any)
  }

  return supabase
}

export default async function handler(
  req: VercelRequest,
  res: VercelResponse
) {
  console.log('ğŸš€ [AI Questions API] ì§ˆë¬¸ ìƒì„± ìš”ì²­ ìˆ˜ì‹ :', {
    timestamp: new Date().toISOString(),
    method: req.method,
    hasBody: !!req.body,
    hasAuth: !!req.headers.authorization
  })

  // CORS í—¤ë” ì¶”ê°€
  res.setHeader('Access-Control-Allow-Origin', '*')
  res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS')
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization')

  // OPTIONS ìš”ì²­ ì²˜ë¦¬
  if (req.method === 'OPTIONS') {
    return res.status(200).end()
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  try {
    // ì¸ì¦ í† í° ì¶”ì¶œ ë° ê²€ì¦
    const authHeader = req.headers.authorization
    let authToken: string | undefined
    let authenticatedUser: any = null

    if (authHeader && authHeader.startsWith('Bearer ')) {
      authToken = authHeader.substring(7)

      try {
        // Supabase í´ë¼ì´ì–¸íŠ¸ë¡œ ì¸ì¦ ê²€ì¦
        const supabase = createServerSupabaseClient(authToken)
        const { data: { user }, error } = await supabase.auth.getUser()

        if (error || !user) {
          console.error('ì¸ì¦ ê²€ì¦ ì‹¤íŒ¨:', error)
        } else {
          authenticatedUser = user
          console.log('ì¸ì¦ ì„±ê³µ:', { userId: user.id, email: user.email })
        }
      } catch (authError) {
        console.error('ì¸ì¦ ì²˜ë¦¬ ì˜¤ë¥˜:', authError)
      }
    }

    const requestBody: QuestionRequest = req.body

    console.log('ğŸ“ [AI Questions API] ìš”ì²­ ë¶„ì„:', {
      provider: requestBody.provider,
      model: requestBody.model,
      projectId: requestBody.projectId,
      documentsCount: requestBody.documents?.length || 0,
      hasProjectInfo: !!requestBody.projectInfo,
      projectName: requestBody.projectInfo?.name,
      authenticatedUserId: authenticatedUser?.id,
      hasAuthToken: !!authToken
    })

    // í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
    if (!requestBody.provider || !requestBody.model || !requestBody.projectId) {
      console.error('âŒ [AI Questions API] í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½:', {
        hasProvider: !!requestBody.provider,
        hasModel: !!requestBody.model,
        hasProjectId: !!requestBody.projectId
      })
      return res.status(400).json({
        error: 'í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.',
        required: ['provider', 'model', 'projectId']
      })
    }

    // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    const apiKeys = {
      openai: process.env['OPENAI_API_KEY'],
      anthropic: process.env['ANTHROPIC_API_KEY'],
      google: process.env['GOOGLE_AI_API_KEY']
    }

    const apiKey = apiKeys[requestBody.provider]
    if (!apiKey) {
      console.error(`âŒ [AI Questions API] ${requestBody.provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`)
      return res.status(500).json({
        error: `${requestBody.provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`,
        provider: requestBody.provider
      })
    }

    console.log(`ğŸ¤– [AI Questions API] AI ì§ˆë¬¸ ìƒì„± ì‹œì‘: ${requestBody.provider} ${requestBody.model}`)

    // AI í”„ë¡¬í”„íŠ¸ ìƒì„±
    const prompt = buildQuestionPrompt(requestBody)
    console.log('ğŸ“„ [AI Questions API] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ, ê¸¸ì´:', prompt.length)

    // AI API í˜¸ì¶œ
    const aiResponse = await callAIForQuestions(
      requestBody.provider,
      apiKey,
      requestBody.model,
      prompt
    )

    console.log('âœ… [AI Questions API] AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ:', {
      contentLength: aiResponse.content?.length || 0,
      inputTokens: aiResponse.usage.inputTokens,
      outputTokens: aiResponse.usage.outputTokens
    })

    // ì‘ë‹µ íŒŒì‹± ë° ì§ˆë¬¸ ì¶”ì¶œ
    const questions = parseQuestions(aiResponse.content)
    console.log('ğŸ“Š [AI Questions API] ì§ˆë¬¸ íŒŒì‹± ì™„ë£Œ:', {
      questionsCount: questions.length,
      categories: [...new Set(questions.map(q => q.category))]
    })

    if (questions.length === 0) {
      throw new Error('AIì—ì„œ ìœ íš¨í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
    }

    const response: QuestionResponse = {
      questions,
      usage: aiResponse.usage,
      cost: aiResponse.cost,
      model: requestBody.model,
      responseTime: aiResponse.responseTime,
      metadata: {
        projectId: requestBody.projectId,
        totalQuestions: questions.length,
        categories: [...new Set(questions.map(q => q.category))]
      }
    }

    console.log(`âœ… [AI Questions API] ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: ${questions.length}ê°œ ì§ˆë¬¸, $${response.cost.totalCost.toFixed(4)}`)
    return res.status(200).json(response)

  } catch (error) {
    console.error('âŒ [AI Questions API] ì˜¤ë¥˜ ìƒì„¸:', {
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      timestamp: new Date().toISOString()
    })

    return res.status(500).json({
      error: 'AI ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      details: error instanceof Error ? error.message : String(error),
      timestamp: new Date().toISOString()
    })
  }
}

function buildQuestionPrompt(request: QuestionRequest): string {
  const { projectInfo, documents, context, preAnalysisData } = request

  // ì‹œì¥ ì¡°ì‚¬ ì§ˆë¬¸ ìƒì„± (ì‚¬ì „ ë¶„ì„ ë°ì´í„° í™œìš©)
  if (context?.requestType === 'market_research_questions') {
    let prompt = `ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ ì‹œì¥ ì¡°ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ì „ ë¶„ì„ ë‹¨ê³„ì—ì„œ ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œì¥ ì¡°ì‚¬ë¥¼ ìœ„í•œ í•µì‹¬ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

í”„ë¡œì íŠ¸ ì •ë³´:
- ì´ë¦„: ${projectInfo?.name || 'ë¯¸ì •'}
- ì„¤ëª…: ${projectInfo?.description || 'ë¯¸ì •'}
- ì‚°ì—… ë¶„ì•¼: ${projectInfo?.industry || 'ë¯¸ì •'}
`

    // ì‚¬ì „ ë¶„ì„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ë¥¼ report ë˜ëŠ” documentAnalysesë¡œ í™•ì¸
    const hasPreAnalysisData = preAnalysisData && (
      (preAnalysisData.report && Object.keys(preAnalysisData.report).length > 0) ||
      (preAnalysisData.documentAnalyses && preAnalysisData.documentAnalyses.length > 0)
    )

    console.log('ğŸ” [buildQuestionPrompt] ì‚¬ì „ ë¶„ì„ ë°ì´í„° ì²´í¬:', {
      hasPreAnalysisData,
      hasReport: !!preAnalysisData?.report,
      reportKeys: preAnalysisData?.report ? Object.keys(preAnalysisData.report).length : 0,
      documentAnalysesCount: preAnalysisData?.documentAnalyses?.length || 0
    })

    if (hasPreAnalysisData) {
      prompt += `\n=== ì‚¬ì „ ë¶„ì„ ë³´ê³ ì„œ ì¸ì‚¬ì´íŠ¸ ===\n`

      if (preAnalysisData.report) {
        prompt += `ë¶„ì„ ìš”ì•½: ${preAnalysisData.report.summary || 'ì—†ìŒ'}\n\n`

        if (preAnalysisData.report.key_findings && preAnalysisData.report.key_findings.length > 0) {
          prompt += `í•µì‹¬ ë°œê²¬ì‚¬í•­:\n${preAnalysisData.report.key_findings.map((f: string) => `- ${f}`).join('\n')}\n\n`
        }

        if (preAnalysisData.report.recommendations && preAnalysisData.report.recommendations.length > 0) {
          prompt += `ê¶Œì¥ì‚¬í•­:\n${preAnalysisData.report.recommendations.map((r: string) => `- ${r}`).join('\n')}\n\n`
        }

        if (preAnalysisData.report.technical_insights && preAnalysisData.report.technical_insights.length > 0) {
          prompt += `ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸:\n${preAnalysisData.report.technical_insights.map((t: string) => `- ${t}`).join('\n')}\n\n`
        }

        if (preAnalysisData.report.market_insights && preAnalysisData.report.market_insights.length > 0) {
          prompt += `ì‹œì¥ ì¸ì‚¬ì´íŠ¸:\n${preAnalysisData.report.market_insights.map((m: string) => `- ${m}`).join('\n')}\n\n`
        }
      }

      if (preAnalysisData.documentAnalyses && preAnalysisData.documentAnalyses.length > 0) {
        prompt += `=== ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ===\n`
        preAnalysisData.documentAnalyses.forEach((analysis: any, index: number) => {
          prompt += `${index + 1}. ${analysis.document_name || 'ë¬¸ì„œ'}\n`
          prompt += `   ìš”ì•½: ${analysis.summary || 'ì—†ìŒ'}\n`
          if (analysis.key_points && analysis.key_points.length > 0) {
            prompt += `   í•µì‹¬ í¬ì¸íŠ¸: ${analysis.key_points.join(', ')}\n`
          }
          if (analysis.technical_details && analysis.technical_details.length > 0) {
            prompt += `   ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­: ${analysis.technical_details.join(', ')}\n`
          }
          prompt += `\n`
        })
      }

      console.log('âœ… [buildQuestionPrompt] ì‚¬ì „ ë¶„ì„ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í–ˆìŠµë‹ˆë‹¤.')
    } else {
      prompt += `\n(ì°¸ê³ : ì´ í”„ë¡œì íŠ¸ì—ëŠ” ì‚¬ì „ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.)\n`
      console.warn('âš ï¸ [buildQuestionPrompt] ì‚¬ì „ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.')
    }

    if (documents && documents.length > 0) {
      prompt += `\nì—…ë¡œë“œëœ ë¬¸ì„œë“¤:
${documents.map((doc, index) => `${index + 1}. ${doc.name}`).join('\n')}
`
    }

    prompt += `\nì‹œì¥ ì¡°ì‚¬ë¥¼ ìœ„í•œ ì§ˆë¬¸ ìƒì„± ìš”êµ¬ì‚¬í•­:
1. **ë°˜ë“œì‹œ** ìœ„ì— ì œê³µëœ ì‚¬ì „ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 6-10ê°œì˜ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
2. ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¥¼ í¬í•¨í•˜ë˜, ê° ì§ˆë¬¸ì€ ì‚¬ì „ ë¶„ì„ì—ì„œ ë°œê²¬ëœ ë‚´ìš©ì„ ì§ì ‘ ì°¸ì¡°í•´ì•¼ í•©ë‹ˆë‹¤:
   - ì‹œì¥ ê·œëª¨ ë° ì„±ì¥ì„±: ì‚¬ì „ ë¶„ì„ì—ì„œ ì–¸ê¸‰ëœ ì‹œì¥ ë°ì´í„°ë¥¼ êµ¬ì²´í™”
   - ê²½ìŸ í™˜ê²½ ë¶„ì„: ì‚¬ì „ ë¶„ì„ì—ì„œ ë°œê²¬ëœ ê²½ìŸì‚¬ë‚˜ ì‹œì¥ ìƒí™©ì„ ì‹¬í™”
   - íƒ€ê²Ÿ ê³ ê°: ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ê³ ê° ì •ë³´ë¥¼ í™•ì¥
   - ì‹œì¥ ì§„ì… ì „ëµ: ê¶Œì¥ì‚¬í•­ê³¼ ë°œê²¬ì‚¬í•­ì„ ì‹¤í–‰ ì „ëµìœ¼ë¡œ ì „í™˜
   - ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­: ê¸°ìˆ  ì¸ì‚¬ì´íŠ¸ë¥¼ êµ¬ì²´ì  ìš”êµ¬ì‚¬í•­ìœ¼ë¡œ ë³€í™˜
3. **ì¤‘ìš”**: ì¼ë°˜ì ì¸ ì§ˆë¬¸ ëŒ€ì‹ , í”„ë¡œì íŠ¸ ê³ ìœ ì˜ ë§¥ë½ì„ ë°˜ì˜í•œ êµ¬ì²´ì  ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
   - ë‚˜ìœ ì˜ˆ: "êµ­ë‚´ AI ì„œë¹„ìŠ¤ ì‹œì¥ì˜ í˜„ì¬ ê·œëª¨ëŠ”?"
   - ì¢‹ì€ ì˜ˆ: "${projectInfo?.name || 'ì´ í”„ë¡œì íŠ¸'}ì˜ ì£¼ìš” ëª©í‘œ ì‹œì¥ì—ì„œ ê²½ìŸ ìš°ìœ„ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•œ í•µì‹¬ ì°¨ë³„í™” ìš”ì†ŒëŠ”?"
4. ê° ì§ˆë¬¸ì˜ helpTextì—ëŠ” ì‚¬ì „ ë¶„ì„ì—ì„œ ë°œê²¬ëœ ê´€ë ¨ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ì„¸ìš”.
5. ë‹µë³€ì„ í†µí•´ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥ í˜•ì‹ (JSON):
{
  "questions": [
    {
      "category": "ì¹´í…Œê³ ë¦¬ëª… (ì˜ˆ: ì‹œì¥ ê·œëª¨, ê²½ìŸ ë¶„ì„, íƒ€ê²Ÿ ê³ ê°)",
      "text": "ì§ˆë¬¸ ë‚´ìš©",
      "type": "text|select|multiselect|number|textarea",
      "options": ["ì˜µì…˜1", "ì˜µì…˜2"] (select/multiselectì¸ ê²½ìš°ë§Œ),
      "required": true|false,
      "helpText": "ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë„ì›€ë§",
      "priority": "high|medium|low",
      "confidence": 0.0-1.0
    }
  ]
}

ì •í™•í•œ JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`

    return prompt
  }

  // í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì§ˆë¬¸ ìƒì„± (ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ í™œìš©)
  if (context?.requestType === 'personas_questions') {
    let prompt = `ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ ì‚¬ìš©ì ê²½í—˜(UX) ì „ë¬¸ê°€ì´ì í˜ë¥´ì†Œë‚˜ ë¶„ì„ê°€ì…ë‹ˆë‹¤. íƒ€ê²Ÿ ê³ ê° í˜ë¥´ì†Œë‚˜ë¥¼ ì •ì˜í•˜ê¸° ìœ„í•œ í•µì‹¬ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

í”„ë¡œì íŠ¸ ì •ë³´:
- ì´ë¦„: ${projectInfo?.name || 'ë¯¸ì •'}
- ì„¤ëª…: ${projectInfo?.description || 'ë¯¸ì •'}
- ì‚°ì—… ë¶„ì•¼: ${projectInfo?.industry || 'ë¯¸ì •'}
`

    // ì‚¬ì „ ë¶„ì„ ë°ì´í„° í™•ì¸
    const hasPreAnalysisData = preAnalysisData && (
      (preAnalysisData.report && Object.keys(preAnalysisData.report).length > 0) ||
      (preAnalysisData.documentAnalyses && preAnalysisData.documentAnalyses.length > 0)
    )

    if (hasPreAnalysisData) {
      prompt += `\n=== ì‚¬ì „ ë¶„ì„ ë³´ê³ ì„œ ì¸ì‚¬ì´íŠ¸ ===\n`

      if (preAnalysisData.report) {
        prompt += `ë¶„ì„ ìš”ì•½: ${preAnalysisData.report.summary || 'ì—†ìŒ'}\n\n`

        if (preAnalysisData.report.key_findings && preAnalysisData.report.key_findings.length > 0) {
          prompt += `í•µì‹¬ ë°œê²¬ì‚¬í•­:\n${preAnalysisData.report.key_findings.map((f: string) => `- ${f}`).join('\n')}\n\n`
        }

        if (preAnalysisData.report.recommendations && preAnalysisData.report.recommendations.length > 0) {
          prompt += `ê¶Œì¥ì‚¬í•­:\n${preAnalysisData.report.recommendations.map((r: string) => `- ${r}`).join('\n')}\n\n`
        }
      }

      if (preAnalysisData.documentAnalyses && preAnalysisData.documentAnalyses.length > 0) {
        prompt += `=== ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ===\n`
        preAnalysisData.documentAnalyses.forEach((analysis: any, index: number) => {
          prompt += `${index + 1}. ${analysis.document_name || 'ë¬¸ì„œ'}\n`
          prompt += `   ìš”ì•½: ${analysis.summary || 'ì—†ìŒ'}\n`
          if (analysis.key_points && analysis.key_points.length > 0) {
            prompt += `   í•µì‹¬ í¬ì¸íŠ¸: ${analysis.key_points.join(', ')}\n`
          }
          prompt += `\n`
        })
      }
    }

    // ì‹œì¥ ì¡°ì‚¬ ë°ì´í„° í™•ì¸ (request.marketResearchData ì¶”ê°€ í•„ìš”)
    const marketResearchData = (request as any).marketResearchData
    if (marketResearchData && marketResearchData.analysis_data) {
      prompt += `\n=== ì‹œì¥ ì¡°ì‚¬ ë¶„ì„ ê²°ê³¼ ===\n`
      const analysisData = marketResearchData.analysis_data

      if (analysisData.market_insights) {
        prompt += `ì‹œì¥ ì¸ì‚¬ì´íŠ¸:\n${analysisData.market_insights}\n\n`
      }

      if (analysisData.target_customers) {
        prompt += `íƒ€ê²Ÿ ê³ ê°:\n${analysisData.target_customers}\n\n`
      }

      if (analysisData.competition_analysis) {
        prompt += `ê²½ìŸ ë¶„ì„:\n${analysisData.competition_analysis}\n\n`
      }
    }

    if (documents && documents.length > 0) {
      prompt += `\nì—…ë¡œë“œëœ ë¬¸ì„œë“¤:
${documents.map((doc, index) => `${index + 1}. ${doc.name}`).join('\n')}
`
    }

    prompt += `\ní˜ë¥´ì†Œë‚˜ ë¶„ì„ ì§ˆë¬¸ ìƒì„± ìš”êµ¬ì‚¬í•­:

**í˜ë¥´ì†Œë‚˜ë€?** ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ íƒ€ê²Ÿ ê³ ê°ì„ ëŒ€í‘œí•˜ëŠ” ê°€ìƒì˜ ì¸ë¬¼ìƒì…ë‹ˆë‹¤. ë‹¤ìŒ ì˜ì—­ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:

1. **ì¸êµ¬í†µê³„í•™ì  ì •ë³´** (Demographics):
   - ì—°ë ¹ëŒ€, ì„±ë³„, ì§€ì—­, ì§ì—…, ì†Œë“ ìˆ˜ì¤€, êµìœ¡ ìˆ˜ì¤€ ë“±
   - ì˜ˆì‹œ ì§ˆë¬¸: "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì˜ ì—°ë ¹ëŒ€ëŠ”?" (multiselect: 20ëŒ€, 30ëŒ€, 40ëŒ€ ë“±)

2. **ì‹¬ë¦¬ì  íŠ¹ì„±** (Psychographics):
   - ê°€ì¹˜ê´€, ë¼ì´í”„ìŠ¤íƒ€ì¼, ê´€ì‹¬ì‚¬, íƒœë„ ë“±
   - ì˜ˆì‹œ ì§ˆë¬¸: "íƒ€ê²Ÿ ê³ ê°ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬ì™€ ê°€ì¹˜ê´€ì€?" (textarea)

3. **í–‰ë™ íŒ¨í„´** (Behavioral):
   - êµ¬ë§¤ íŒ¨í„´, ì œí’ˆ ì‚¬ìš© ë¹ˆë„, ì •ë³´ íƒìƒ‰ ë°©ì‹, ì˜ì‚¬ê²°ì • ê³¼ì • ë“±
   - ì˜ˆì‹œ ì§ˆë¬¸: "êµ¬ë§¤ ì˜ì‚¬ê²°ì • ì‹œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•˜ëŠ” ìš”ì¸ì€?" (multiselect)

4. **ëª©í‘œì™€ ë™ê¸°** (Goals & Motivations):
   - ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” ëª©í‘œ, ì œí’ˆ/ì„œë¹„ìŠ¤ë¥¼ ì°¾ëŠ” ì´ìœ 
   - ì˜ˆì‹œ ì§ˆë¬¸: "ê³ ê°ì´ ì´ ì œí’ˆ/ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í•´ê²°í•˜ë ¤ëŠ” í•µì‹¬ ë¬¸ì œëŠ”?" (textarea)

5. **Pain Points (ê³ ì¶©ì )**:
   - í˜„ì¬ ê²ªê³  ìˆëŠ” ë¬¸ì œì , ë¶ˆí¸í•¨, ë¶ˆë§Œ ì‚¬í•­
   - ì˜ˆì‹œ ì§ˆë¬¸: "ê¸°ì¡´ ì†”ë£¨ì…˜ ì‚¬ìš© ì‹œ ê°€ì¥ í° ë¶ˆí¸ ì‚¬í•­ì€?" (textarea)

6. **ì±„ë„ ë° ì ‘ì ** (Channels & Touchpoints):
   - ì •ë³´ íšë“ ê²½ë¡œ, ì„ í˜¸í•˜ëŠ” ì†Œí†µ ì±„ë„, ë¯¸ë””ì–´ ì†Œë¹„ ìŠµê´€
   - ì˜ˆì‹œ ì§ˆë¬¸: "íƒ€ê²Ÿ ê³ ê°ì´ ê°€ì¥ ìì£¼ ì‚¬ìš©í•˜ëŠ” ì†Œí†µ ì±„ë„ì€?" (multiselect: ì´ë©”ì¼, SNS, ë¸”ë¡œê·¸ ë“±)

**ì¤‘ìš”í•œ ì›ì¹™:**
- 6-10ê°œì˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”
- ê° ì§ˆë¬¸ì€ ìœ„ 6ê°€ì§€ ì˜ì—­ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ë‹¤ë¤„ì•¼ í•©ë‹ˆë‹¤
- **ì ˆëŒ€ë¡œ** í”„ë¡œì íŠ¸ ì¼ì •, ì˜ˆì‚°, ê¸°ìˆ  ìŠ¤íƒ, ë³´ì•ˆ ì •ì±… ë“± í”„ë¡œì íŠ¸ ê´€ë¦¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”
- ëª¨ë“  ì§ˆë¬¸ì€ "íƒ€ê²Ÿ ê³ ê°"ì— ëŒ€í•œ ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤ (í”„ë¡œì íŠ¸ ìì²´ê°€ ì•„ë‹˜)
- ì‚¬ì „ ë¶„ì„ ë° ì‹œì¥ ì¡°ì‚¬ì—ì„œ ë°œê²¬ëœ íƒ€ê²Ÿ ê³ ê° ê´€ë ¨ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°˜ì˜í•˜ì„¸ìš”
- typeì€ text, select, multiselect, number, textarea ì¤‘ ì„ íƒí•˜ì„¸ìš”

**ë‚˜ìœ ì˜ˆì‹œ (ì ˆëŒ€ ì•ˆ ë¨):**
âŒ "í”„ë¡œì íŠ¸ ì˜ˆì‚° ë²”ìœ„ëŠ”?" - ì´ê±´ í”„ë¡œì íŠ¸ ì§ˆë¬¸ì´ì§€ í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ì´ ì•„ë‹˜
âŒ "ì£¼ìš” ë§ˆì¼ìŠ¤í†¤ì€?" - ì´ê±´ ì¼ì • ì§ˆë¬¸ì´ì§€ ê³ ê° í˜ë¥´ì†Œë‚˜ ì§ˆë¬¸ì´ ì•„ë‹˜
âŒ "í•„ìš”í•œ AI ê¸°ìˆ ì€?" - ì´ê±´ ê¸°ìˆ  ìš”êµ¬ì‚¬í•­ì´ì§€ ê³ ê° íŠ¹ì„±ì´ ì•„ë‹˜

**ì¢‹ì€ ì˜ˆì‹œ:**
âœ… "ì£¼ìš” íƒ€ê²Ÿ ê³ ê°ì˜ ì—°ë ¹ëŒ€ëŠ”?" (ì¸êµ¬í†µê³„)
âœ… "ê³ ê°ì´ ì œí’ˆ/ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ëª©ì ì€?" (ëª©í‘œì™€ ë™ê¸°)
âœ… "ê³ ê°ì˜ ê¸°ìˆ  ìˆ™ë ¨ë„ëŠ”?" (í–‰ë™ íŒ¨í„´)
âœ… "êµ¬ë§¤ ì˜ì‚¬ê²°ì •ì— ì˜í–¥ì„ ì£¼ëŠ” ì£¼ìš” ìš”ì¸ì€?" (í–‰ë™ íŒ¨í„´)
âœ… "íƒ€ê²Ÿ ê³ ê°ì´ í˜„ì¬ ê²ªê³  ìˆëŠ” ê°€ì¥ í° ë¶ˆí¸ì€?" (Pain Points)

ì¶œë ¥ í˜•ì‹ (JSON):
{
  "questions": [
    {
      "category": "ì¹´í…Œê³ ë¦¬ëª… (ì¸êµ¬í†µê³„, ì‹¬ë¦¬íŠ¹ì„±, í–‰ë™íŒ¨í„´, ëª©í‘œ/ë™ê¸°, Pain Points, ì†Œí†µì±„ë„ ì¤‘ í•˜ë‚˜)",
      "text": "ì§ˆë¬¸ ë‚´ìš©",
      "type": "text|select|multiselect|number|textarea",
      "options": ["ì˜µì…˜1", "ì˜µì…˜2"] (select/multiselectì¸ ê²½ìš°ë§Œ),
      "required": true|false,
      "helpText": "ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë„ì›€ë§",
      "priority": "high|medium|low",
      "confidence": 0.0-1.0
    }
  ]
}

ì •í™•í•œ JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`

    return prompt
  }

  // ì‚¬ì „ ë¶„ì„ ì§ˆë¬¸ ìƒì„± (ê¸°ì¡´ ë¡œì§)
  let prompt = `ë‹¹ì‹ ì€ ì „ë¬¸ í”„ë¡œì íŠ¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ì „ ë¶„ì„ ë‹¨ê³„ì—ì„œ í•„ìš”í•œ í•µì‹¬ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

í”„ë¡œì íŠ¸ ì •ë³´:
- ì´ë¦„: ${projectInfo?.name || 'ë¯¸ì •'}
- ì„¤ëª…: ${projectInfo?.description || 'ë¯¸ì •'}
- ì‚°ì—… ë¶„ì•¼: ${projectInfo?.industry || 'ë¯¸ì •'}
`

  if (documents && documents.length > 0) {
    prompt += `\nì—…ë¡œë“œëœ ë¬¸ì„œë“¤:
${documents.map((doc, index) => `${index + 1}. ${doc.name}${doc.summary ? ` - ${doc.summary}` : ''}`).join('\n')}
`
  }

  prompt += `
ìš”êµ¬ì‚¬í•­:
1. í”„ë¡œì íŠ¸ íŠ¹ì„±ì— ë§ëŠ” 5-8ê°œì˜ í•µì‹¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
2. ê° ì§ˆë¬¸ì€ í”„ë¡œì íŠ¸ ì´í•´ë¥¼ ë•ëŠ” ì‹¤ì§ˆì ì¸ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•œ ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.
3. ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬(ê¸°ìˆ , ë¹„ì¦ˆë‹ˆìŠ¤, ì¼ì •, ì˜ˆì‚°, ìœ„í—˜ ë“±)ë¥¼ í¬í•¨í•˜ì„¸ìš”.
4. ê° ì§ˆë¬¸ì˜ ì¤‘ìš”ë„ì™€ ì‹ ë¢°ë„ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSON):
{
  "questions": [
    {
      "category": "ì¹´í…Œê³ ë¦¬ëª…",
      "text": "ì§ˆë¬¸ ë‚´ìš©",
      "type": "text|select|multiselect|number|textarea",
      "options": ["ì˜µì…˜1", "ì˜µì…˜2"] (select/multiselectì¸ ê²½ìš°),
      "required": true|false,
      "helpText": "ì§ˆë¬¸ì— ëŒ€í•œ ë„ì›€ë§",
      "priority": "high|medium|low",
      "confidence": 0.0-1.0
    }
  ]
}

ì •í™•í•œ JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`

  return prompt
}

async function callAIForQuestions(
  provider: string,
  apiKey: string,
  model: string,
  prompt: string
): Promise<any> {
  const startTime = Date.now()

  let response: Response
  let requestBody: any

  switch (provider) {
    case 'anthropic':
      response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
          model,
          max_tokens: 3000,
          temperature: 0.7,
          messages: [{ role: 'user', content: prompt }]
        })
      })
      break

    case 'openai':
      response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model,
          messages: [{ role: 'user', content: prompt }],
          max_tokens: 3000,
          temperature: 0.7
        })
      })
      break

    case 'google':
      response = await fetch(
        `https://generativelanguage.googleapis.com/v1/models/${model}:generateContent?key=${apiKey}`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents: [{ parts: [{ text: prompt }] }],
            generationConfig: {
              maxOutputTokens: 3000,
              temperature: 0.7
            }
          })
        }
      )
      break

    default:
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: ${provider}`)
  }

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`${provider} API ì˜¤ë¥˜: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  const responseTime = Date.now() - startTime

  let content: string
  let usage: any
  let cost: any

  switch (provider) {
    case 'anthropic':
      content = data.content[0].text
      const inputTokens = estimateTokens(prompt)
      const outputTokens = estimateTokens(content)
      const pricing = getAnthropicPricing(model)
      usage = {
        inputTokens,
        outputTokens,
        totalTokens: inputTokens + outputTokens
      }
      cost = {
        inputCost: (inputTokens * pricing.inputCost) / 1000000,
        outputCost: (outputTokens * pricing.outputCost) / 1000000,
        totalCost: ((inputTokens * pricing.inputCost) + (outputTokens * pricing.outputCost)) / 1000000
      }
      break

    case 'openai':
      content = data.choices[0].message.content
      const openaiPricing = getOpenAIPricing(model)
      usage = {
        inputTokens: data.usage.prompt_tokens,
        outputTokens: data.usage.completion_tokens,
        totalTokens: data.usage.total_tokens
      }
      cost = {
        inputCost: (data.usage.prompt_tokens * openaiPricing.inputCost) / 1000000,
        outputCost: (data.usage.completion_tokens * openaiPricing.outputCost) / 1000000,
        totalCost: ((data.usage.prompt_tokens * openaiPricing.inputCost) + (data.usage.completion_tokens * openaiPricing.outputCost)) / 1000000
      }
      break

    case 'google':
      content = data.candidates[0].content.parts[0].text
      const googleInputTokens = estimateTokens(prompt)
      const googleOutputTokens = estimateTokens(content)
      const googlePricing = getGoogleAIPricing(model)
      usage = {
        inputTokens: googleInputTokens,
        outputTokens: googleOutputTokens,
        totalTokens: googleInputTokens + googleOutputTokens
      }
      cost = {
        inputCost: (googleInputTokens * googlePricing.inputCost) / 1000000,
        outputCost: (googleOutputTokens * googlePricing.outputCost) / 1000000,
        totalCost: ((googleInputTokens * googlePricing.inputCost) + (googleOutputTokens * googlePricing.outputCost)) / 1000000
      }
      break

    default:
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: ${provider}`)
  }

  return {
    content,
    usage,
    cost,
    responseTime
  }
}

function parseQuestions(response: string): GeneratedQuestion[] {
  try {
    // JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
    const jsonMatch = response.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    }

    const parsed = JSON.parse(jsonMatch[0])

    if (!parsed.questions || !Array.isArray(parsed.questions)) {
      throw new Error('questions ë°°ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
    }

    return parsed.questions.map((q: any) => ({
      category: q.category || 'ê¸°íƒ€',
      text: q.text || '',
      type: q.type || 'textarea',
      options: q.options,
      required: q.required || false,
      helpText: q.helpText || '',
      priority: q.priority || 'medium',
      confidence: q.confidence || 0.8
    })).filter((q: GeneratedQuestion) => q.text.trim() !== '')

  } catch (error) {
    console.error('ì§ˆë¬¸ íŒŒì‹± ì‹¤íŒ¨:', error)

    // íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜
    return [
      {
        category: 'í”„ë¡œì íŠ¸ ê°œìš”',
        text: 'ì´ í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ëª©í‘œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?',
        type: 'textarea',
        required: true,
        helpText: 'í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ëª©ì ê³¼ ê¸°ëŒ€ íš¨ê³¼ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.',
        priority: 'high',
        confidence: 0.9
      },
      {
        category: 'ê¸°ìˆ  ìš”êµ¬ì‚¬í•­',
        text: 'í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?',
        type: 'textarea',
        required: true,
        helpText: 'ì‚¬ìš©í•  í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤ ë“±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.',
        priority: 'high',
        confidence: 0.9
      },
      {
        category: 'ì¼ì • ê´€ë¦¬',
        text: 'í”„ë¡œì íŠ¸ ì™„ë£Œ ëª©í‘œ ì‹œì ì€ ì–¸ì œì…ë‹ˆê¹Œ?',
        type: 'text',
        required: true,
        helpText: 'ì˜ˆìƒ ì™„ë£Œ ë‚ ì§œë‚˜ ê¸°ê°„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.',
        priority: 'high',
        confidence: 0.9
      }
    ]
  }
}

// í† í° ì¶”ì • í•¨ìˆ˜
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4) // 1í† í° â‰ˆ 4ê¸€ì
}

// ê°€ê²© ì •ë³´ í•¨ìˆ˜ë“¤
function getAnthropicPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'claude-sonnet-4-20250514': { inputCost: 3, outputCost: 15 },
    'claude-3-5-sonnet-20241022': { inputCost: 3, outputCost: 15 },
    'claude-3-opus-20240229': { inputCost: 15, outputCost: 75 },
    'claude-3-haiku-20240307': { inputCost: 0.25, outputCost: 1.25 }
  }
  return pricing[model] || { inputCost: 3, outputCost: 15 }
}

function getOpenAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gpt-4o': { inputCost: 5, outputCost: 15 },
    'gpt-4o-mini': { inputCost: 0.15, outputCost: 0.6 },
    'gpt-4-turbo': { inputCost: 10, outputCost: 30 },
    'gpt-3.5-turbo': { inputCost: 0.5, outputCost: 1.5 }
  }
  return pricing[model] || { inputCost: 5, outputCost: 15 }
}

function getGoogleAIPricing(model: string): { inputCost: number; outputCost: number } {
  const pricing: Record<string, { inputCost: number; outputCost: number }> = {
    'gemini-2.0-flash-exp': { inputCost: 0.075, outputCost: 0.3 },
    'gemini-1.5-pro': { inputCost: 1.25, outputCost: 5 },
    'gemini-1.5-flash': { inputCost: 0.075, outputCost: 0.3 }
  }
  return pricing[model] || { inputCost: 1.25, outputCost: 5 }
}