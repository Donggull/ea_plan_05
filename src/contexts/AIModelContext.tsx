import React, { createContext, useContext, useReducer, useEffect, useState } from 'react'
import { modelSettingsService } from '../services/ai/modelSettingsService'
import { modelSyncService } from '../services/ai/modelSyncService'
import { getRecommendedModels } from '../services/ai/latestModelsData'
import { aiServiceManager } from '../services/ai/AIServiceManager'

// AI ëª¨ë¸ íƒ€ì… ì •ì˜
export interface AIModel {
  id: string
  name: string
  provider: 'openai' | 'anthropic' | 'google' | 'custom'
  model_id: string
  cost_per_input_token: number
  cost_per_output_token: number
  status: string
  capabilities: string[]
  max_tokens: number
  available: boolean
}

// ìƒíƒœ íƒ€ì… ì •ì˜
interface AIModelState {
  selectedProviderId: string | null  // 1ì°¨ ì„ íƒ: í”„ë¡œë°”ì´ë”
  selectedModelId: string | null     // 2ì°¨ ì„ íƒ: ì„¸ë¶€ ëª¨ë¸
  availableModels: AIModel[]
  loading: boolean
  error: string | null
  lastSyncTime: string | null
  syncInProgress: boolean
}

// ì•¡ì…˜ íƒ€ì… ì •ì˜
type AIModelAction =
  | { type: 'SET_LOADING'; payload: boolean }
  | { type: 'SET_ERROR'; payload: string | null }
  | { type: 'SET_MODELS'; payload: AIModel[] }
  | { type: 'SELECT_PROVIDER'; payload: string }
  | { type: 'SELECT_MODEL'; payload: string }
  | { type: 'CLEAR_SELECTION' }
  | { type: 'SET_SYNC_STATUS'; payload: { syncInProgress: boolean; lastSyncTime?: string } }

// ì´ˆê¸° ìƒíƒœ
const initialState: AIModelState = {
  selectedProviderId: null,
  selectedModelId: null,
  availableModels: [],
  loading: false,
  error: null,
  lastSyncTime: null,
  syncInProgress: false
}

// ë¦¬ë“€ì„œ
function aiModelReducer(state: AIModelState, action: AIModelAction): AIModelState {
  switch (action.type) {
    case 'SET_LOADING':
      return { ...state, loading: action.payload }
    case 'SET_ERROR':
      return { ...state, error: action.payload, loading: false }
    case 'SET_MODELS':
      return { ...state, availableModels: action.payload, loading: false }
    case 'SELECT_PROVIDER':
      return {
        ...state,
        selectedProviderId: action.payload,
        selectedModelId: null // í”„ë¡œë°”ì´ë” ë³€ê²½ ì‹œ ëª¨ë¸ ì„ íƒ ì´ˆê¸°í™”
      }
    case 'SELECT_MODEL':
      return { ...state, selectedModelId: action.payload }
    case 'CLEAR_SELECTION':
      return { ...state, selectedProviderId: null, selectedModelId: null }
    case 'SET_SYNC_STATUS':
      return {
        ...state,
        syncInProgress: action.payload.syncInProgress,
        lastSyncTime: action.payload.lastSyncTime || state.lastSyncTime
      }
    default:
      return state
  }
}

// ì»¨í…ìŠ¤íŠ¸ íƒ€ì… ì •ì˜
interface AIModelContextType {
  state: AIModelState
  selectProvider: (providerId: string) => Promise<void>
  selectModel: (modelId: string) => Promise<void>
  clearSelection: () => void
  refreshModels: () => Promise<void>
  syncModels: () => Promise<void>
  getSelectedModel: () => AIModel | null
  getProviderModels: (providerId: string) => AIModel[]
  getAvailableProviders: () => string[]
  getRecommendedModels: () => {
    fastest: AIModel | null
    cheapest: AIModel | null
    best_performance: AIModel | null
    balanced: AIModel | null
  }
  getModelStatistics: () => Promise<any>
  isSyncing: boolean
}

// ì»¨í…ìŠ¤íŠ¸ ìƒì„±
const AIModelContext = createContext<AIModelContextType | undefined>(undefined)

// í”„ë¡œë°”ì´ë” ì»´í¬ë„ŒíŠ¸
export function AIModelProvider({ children }: { children: React.ReactNode }) {
  const [state, dispatch] = useReducer(aiModelReducer, initialState)
  const [isSyncing, setIsSyncing] = useState(false)

  // AI ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € í†µí•©)
  const loadModels = async () => {
    try {
      dispatch({ type: 'SET_LOADING', payload: true })
      dispatch({ type: 'SET_ERROR', payload: null })

      // ê¸°ì¡´ ëª¨ë¸ ì„¤ì •ê³¼ AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €ì˜ ëª¨ë¸ì„ ëª¨ë‘ ë¡œë“œ
      const [localModels, aiManagerModels] = await Promise.all([
        modelSettingsService.getActiveModels(),
        aiServiceManager.getAllModels()
      ])

      // ë¡œì»¬ ëª¨ë¸ í¬ë§·íŒ…
      const formattedLocalModels: AIModel[] = localModels.map(model => ({
        id: model.id,
        name: model.name,
        provider: model.provider as 'openai' | 'anthropic' | 'google' | 'custom',
        model_id: model.model_id,
        cost_per_input_token: model.cost_per_input_token,
        cost_per_output_token: model.cost_per_output_token,
        status: model.status || 'active',
        capabilities: model.capabilities || [],
        max_tokens: model.max_tokens,
        available: model.status === 'active'
      }))

      // AI ë§¤ë‹ˆì € ëª¨ë¸ê³¼ ë³‘í•© (ì¤‘ë³µ ì œê±°)
      const allModels = [...formattedLocalModels]
      aiManagerModels.forEach(aiModel => {
        const exists = allModels.find(model => model.model_id === aiModel.model_id)
        if (!exists) {
          allModels.push(aiModel)
        }
      })

      dispatch({ type: 'SET_MODELS', payload: allModels })

      // ê¸°ë³¸ í”„ë¡œë°”ì´ë” ë° ëª¨ë¸ ì„ íƒ (ìµœì‹  Claude 4 Sonnet ìš°ì„ )
      if (allModels.length > 0 && !state.selectedProviderId) {
        const recommended = getRecommendedModels()
        // Claude 4 Sonnetì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒ (ìµœì‹  ëª¨ë¸)
        const defaultModel = allModels.find(m => m.model_id === 'claude-sonnet-4-20250514') ||
                           allModels.find(m => m.model_id === recommended.balanced.model_id) ||
                           allModels[0]

        console.log('ğŸ¯ ê¸°ë³¸ ëª¨ë¸ ì„¤ì •:', {
          selectedModel: defaultModel.name,
          modelId: defaultModel.model_id,
          provider: defaultModel.provider,
          isLatestGeneration: defaultModel.metadata?.latest_generation
        })

        dispatch({ type: 'SELECT_PROVIDER', payload: defaultModel.provider })
        dispatch({ type: 'SELECT_MODEL', payload: defaultModel.id })

        // AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €ì—ë„ ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        await setupAIServiceManager(defaultModel)
      }

      // ë§ˆì§€ë§‰ ë™ê¸°í™” ì‹œê°„ ì—…ë°ì´íŠ¸
      const lastSync = modelSyncService.getLastSyncTime()
      if (lastSync) {
        dispatch({ type: 'SET_SYNC_STATUS', payload: { syncInProgress: false, lastSyncTime: lastSync } })
      }
    } catch (error) {
      console.error('Failed to load AI models:', error)
      dispatch({ type: 'SET_ERROR', payload: 'AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' })
    }
  }

  // AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ì„¤ì • í•¨ìˆ˜
  const setupAIServiceManager = async (model: AIModel) => {
    try {
      // í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
      const apiKeys = {
        openai: import.meta.env.VITE_OPENAI_API_KEY,
        anthropic: import.meta.env.VITE_ANTHROPIC_API_KEY,
        google: import.meta.env.VITE_GOOGLE_AI_API_KEY
      }

      const apiKey = apiKeys[model.provider as keyof typeof apiKeys]
      if (apiKey) {
        await aiServiceManager.setProvider(model.provider, apiKey)
      }
    } catch (error) {
      console.error('AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € ì„¤ì • ì‹¤íŒ¨:', error)
    }
  }

  // AI ëª¨ë¸ ë™ê¸°í™” í•¨ìˆ˜
  const syncModels = async () => {
    try {
      setIsSyncing(true)
      dispatch({ type: 'SET_SYNC_STATUS', payload: { syncInProgress: true } })
      dispatch({ type: 'SET_ERROR', payload: null })

      console.log('ğŸ”„ AI ëª¨ë¸ ë™ê¸°í™” ì‹œì‘...')
      const result = await modelSyncService.syncAllModels()

      if (result.success) {
        console.log('âœ… AI ëª¨ë¸ ë™ê¸°í™” ì™„ë£Œ:', result.summary)
        // ë™ê¸°í™” í›„ ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨
        await loadModels()
      } else {
        console.error('âŒ AI ëª¨ë¸ ë™ê¸°í™” ì‹¤íŒ¨:', result.details.errors)
        dispatch({ type: 'SET_ERROR', payload: `ë™ê¸°í™” ì‹¤íŒ¨: ${result.summary.errors}ê°œ ì˜¤ë¥˜ ë°œìƒ` })
      }

      dispatch({ type: 'SET_SYNC_STATUS', payload: {
        syncInProgress: false,
        lastSyncTime: new Date().toISOString()
      } })
    } catch (error) {
      console.error('AI ëª¨ë¸ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜:', error)
      dispatch({ type: 'SET_ERROR', payload: 'AI ëª¨ë¸ ë™ê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' })
      dispatch({ type: 'SET_SYNC_STATUS', payload: { syncInProgress: false } })
    } finally {
      setIsSyncing(false)
    }
  }

  // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ëª¨ë¸ ë¡œë”©
  useEffect(() => {
    loadModels()
  }, [])

  // ì»¨í…ìŠ¤íŠ¸ ê°’
  const contextValue: AIModelContextType = {
    state,
    selectProvider: async (providerId: string) => {
      dispatch({ type: 'SELECT_PROVIDER', payload: providerId })

      // AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €ì—ë„ ë°˜ì˜
      const selectedModel = state.availableModels.find(m => m.provider === providerId)
      if (selectedModel) {
        await setupAIServiceManager(selectedModel)
      }
    },
    selectModel: async (modelId: string) => {
      dispatch({ type: 'SELECT_MODEL', payload: modelId })

      // AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì €ì—ë„ ë°˜ì˜
      const selectedModel = state.availableModels.find(m => m.id === modelId)
      if (selectedModel) {
        await setupAIServiceManager(selectedModel)
      }
    },
    clearSelection: () => {
      dispatch({ type: 'CLEAR_SELECTION' })
    },
    refreshModels: loadModels,
    syncModels: syncModels,
    getSelectedModel: () => {
      return state.availableModels.find(model => model.id === state.selectedModelId) || null
    },
    getProviderModels: (providerId: string) => {
      return state.availableModels.filter(model => model.provider === providerId)
    },
    getAvailableProviders: () => {
      const providers = [...new Set(state.availableModels.map(model => model.provider))]
      return providers
    },
    getRecommendedModels: () => {
      const recommended = getRecommendedModels()
      return {
        fastest: state.availableModels.find(m => m.model_id === recommended.fastest.model_id) || null,
        cheapest: state.availableModels.find(m => m.model_id === recommended.cheapest.model_id) || null,
        best_performance: state.availableModels.find(m => m.model_id === recommended.best_performance.model_id) || null,
        balanced: state.availableModels.find(m => m.model_id === recommended.balanced.model_id) || null
      }
    },
    getModelStatistics: async () => {
      return await modelSyncService.getModelStatistics()
    },
    isSyncing: isSyncing
  }

  return (
    <AIModelContext.Provider value={contextValue}>
      {children}
    </AIModelContext.Provider>
  )
}

// ì»¤ìŠ¤í…€ í›…
export function useAIModel() {
  const context = useContext(AIModelContext)
  if (context === undefined) {
    throw new Error('useAIModel must be used within an AIModelProvider')
  }
  return context
}

// ì„ íƒëœ ëª¨ë¸ë§Œ ê°€ì ¸ì˜¤ëŠ” í›…
export function useSelectedAIModel() {
  const { state, getSelectedModel } = useAIModel()
  return {
    selectedModel: getSelectedModel(),
    isLoading: state.loading,
    error: state.error
  }
}

// ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ë§Œ ê°€ì ¸ì˜¤ëŠ” í›…
export function useAvailableAIModels() {
  const { state } = useAIModel()
  return {
    models: state.availableModels.filter(model => model.available),
    allModels: state.availableModels,
    isLoading: state.loading,
    error: state.error
  }
}