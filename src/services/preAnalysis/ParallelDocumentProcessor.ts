// import { DocumentAnalysisService } from './DocumentAnalysisService';
// import type { AIModelConfig, DocumentAnalysisResult } from '@/types/preAnalysis';

// ì„ì‹œ íƒ€ì… ì •ì˜ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì˜¬ë°”ë¥¸ import ì‚¬ìš©)
interface AIModelConfig {
  model: string;
  provider: string;
  temperature?: number;
}

interface DocumentAnalysisResult {
  summary: string;
  keyRequirements: string[];
  risks: string[];
  timeline: string[];
  stakeholders: string[];
  technicalStack: string[];
  constraints: string[];
  opportunities: string[];
  processingTime: number;
  model: string;
  provider: string;
  confidence: number;
  inputTokens: number;
  outputTokens: number;
  cost: number;
  metadata?: any;
}

export interface DocumentTask {
  id: string;
  fileName: string;
  content: string;
  priority: number; // 1 (highest) to 5 (lowest)
  estimatedTokens: number;
}

export interface ProcessingOptions {
  maxConcurrency: number;
  batchSize: number;
  timeoutMs: number;
  retryAttempts: number;
  priorityBased: boolean;
}

export interface ProcessingResult {
  success: boolean;
  completedTasks: Array<{
    taskId: string;
    fileName: string;
    result: DocumentAnalysisResult;
    processingTime: number;
  }>;
  failedTasks: Array<{
    taskId: string;
    fileName: string;
    error: string;
    retryCount: number;
  }>;
  totalProcessingTime: number;
  totalTokensUsed: number;
  totalCost: number;
  performance: {
    throughput: number; // docs per second
    averageProcessingTime: number;
    concurrencyUtilization: number;
  };
}

export class ParallelDocumentProcessor {
  private static instance: ParallelDocumentProcessor | null = null;
  // private documentAnalysisService: DocumentAnalysisService;
  private activeJobs: Map<string, Promise<any>>;
  private processingQueue: DocumentTask[];
  private concurrencyLimit: number;

  private constructor() {
    // this.documentAnalysisService = DocumentAnalysisService.getInstance();
    this.activeJobs = new Map();
    this.processingQueue = [];
    this.concurrencyLimit = 3; // ê¸°ë³¸ê°’
  }

  public static getInstance(): ParallelDocumentProcessor {
    if (!ParallelDocumentProcessor.instance) {
      ParallelDocumentProcessor.instance = new ParallelDocumentProcessor();
    }
    return ParallelDocumentProcessor.instance;
  }

  /**
   * ë‹¤ì¤‘ ë¬¸ì„œë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„ ì²˜ë¦¬
   */
  public async processDocuments(
    documents: DocumentTask[],
    sessionId: string,
    modelConfig: AIModelConfig,
    options: Partial<ProcessingOptions> = {}
  ): Promise<ProcessingResult> {
    const startTime = Date.now();

    const processingOptions: ProcessingOptions = {
      maxConcurrency: 3,
      batchSize: 5,
      timeoutMs: 30000,
      retryAttempts: 2,
      priorityBased: true,
      ...options
    };

    // ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì •ë ¬
    const sortedDocuments = processingOptions.priorityBased
      ? [...documents].sort((a, b) => a.priority - b.priority)
      : documents;

    const completedTasks: ProcessingResult['completedTasks'] = [];
    const failedTasks: ProcessingResult['failedTasks'] = [];
    let totalTokensUsed = 0;
    let totalCost = 0;

    // ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°°ì¹˜ ìƒì„±
    const batches = this.createBatches(sortedDocuments, processingOptions.batchSize);

    console.log(`ğŸ“„ ë³‘ë ¬ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘: ${documents.length}ê°œ ë¬¸ì„œ, ${batches.length}ê°œ ë°°ì¹˜`);

    // ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë˜, ë°°ì¹˜ ë‚´ì—ì„œëŠ” ë³‘ë ¬ ì²˜ë¦¬
    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i];
      console.log(`âš¡ ë°°ì¹˜ ${i + 1}/${batches.length} ì²˜ë¦¬ ì¤‘ (${batch.length}ê°œ ë¬¸ì„œ)`);

      // ë°°ì¹˜ ë‚´ ë³‘ë ¬ ì²˜ë¦¬
      const batchPromises = batch.map(document =>
        this.processDocumentWithRetry(
          document,
          sessionId,
          modelConfig,
          processingOptions.retryAttempts,
          processingOptions.timeoutMs
        )
      );

      // ë°°ì¹˜ ì™„ë£Œ ëŒ€ê¸°
      const batchResults = await Promise.allSettled(batchPromises);

      // ê²°ê³¼ ì²˜ë¦¬
      batchResults.forEach((result, index) => {
        const document = batch[index];

        if (result.status === 'fulfilled' && result.value.success) {
          const analysisResult = result.value.data!;
          completedTasks.push({
            taskId: document.id,
            fileName: document.fileName,
            result: analysisResult,
            processingTime: analysisResult.processingTime || 0
          });

          totalTokensUsed += analysisResult.inputTokens + analysisResult.outputTokens;
          totalCost += analysisResult.cost;
        } else {
          const error = result.status === 'rejected'
            ? result.reason.message
            : result.value.error;

          failedTasks.push({
            taskId: document.id,
            fileName: document.fileName,
            error,
            retryCount: processingOptions.retryAttempts
          });
        }
      });

      // ë°°ì¹˜ ê°„ ê°„ê²© (API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€)
      if (i < batches.length - 1) {
        await this.delay(1000);
      }
    }

    const totalProcessingTime = Date.now() - startTime;

    // ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    const performance = this.calculatePerformanceMetrics(
      completedTasks,
      totalProcessingTime,
      processingOptions.maxConcurrency
    );

    console.log(`âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: ${completedTasks.length}ê°œ ì„±ê³µ, ${failedTasks.length}ê°œ ì‹¤íŒ¨`);
    console.log(`ğŸ“Š ì²˜ë¦¬ëŸ‰: ${performance.throughput.toFixed(2)} docs/sec`);

    return {
      success: failedTasks.length === 0,
      completedTasks,
      failedTasks,
      totalProcessingTime,
      totalTokensUsed,
      totalCost,
      performance
    };
  }

  /**
   * ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë¬¸ì„œ ì²˜ë¦¬
   */
  private async processDocumentWithRetry(
    document: DocumentTask,
    _sessionId: string,
    modelConfig: AIModelConfig,
    maxRetries: number,
    timeoutMs: number
  ): Promise<{ success: boolean; data?: DocumentAnalysisResult; error?: string }> {
    let lastError: string = '';

    for (let attempt = 1; attempt <= maxRetries + 1; attempt++) {
      try {
        console.log(`ğŸ”„ ë¬¸ì„œ ì²˜ë¦¬ ì‹œë„ ${attempt}/${maxRetries + 1}: ${document.fileName}`);

        // íƒ€ì„ì•„ì›ƒ ì„¤ì • - ì„ì‹œ ëª¨í‚¹ (ì‹¤ì œ êµ¬í˜„ ì‹œ DocumentAnalysisService ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
        const shouldSucceed = Math.random() > 0.1; // 90% ì„±ê³µë¥ 
        const analysisPromise = Promise.resolve(
          shouldSucceed ? {
            success: true,
            data: {
              summary: `ë¶„ì„ ì™„ë£Œ: ${document.fileName}`,
              keyRequirements: ['ìš”êµ¬ì‚¬í•­ 1', 'ìš”êµ¬ì‚¬í•­ 2'],
              risks: ['ìœ„í—˜ ìš”ì†Œ 1'],
              timeline: ['1ì£¼ì°¨', '2ì£¼ì°¨'],
              stakeholders: ['ì´í•´ê´€ê³„ì 1'],
              technicalStack: ['ê¸°ìˆ  1', 'ê¸°ìˆ  2'],
              constraints: ['ì œì•½ì‚¬í•­ 1'],
              opportunities: ['ê¸°íšŒ ìš”ì†Œ 1'],
              processingTime: Math.random() * 1000 + 500,
              model: modelConfig.model,
              provider: modelConfig.provider,
              confidence: 0.85,
              inputTokens: Math.floor(document.estimatedTokens * 0.8),
              outputTokens: Math.floor(document.estimatedTokens * 0.2),
              cost: Math.random() * 0.01 + 0.001,
              metadata: {}
            }
          } : {
            success: false,
            error: 'ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ'
          }
        );

        const timeoutPromise = new Promise<never>((_, reject) => {
          setTimeout(() => reject(new Error('ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼')), timeoutMs);
        });

        const result = await Promise.race([analysisPromise, timeoutPromise]);

        if (result.success) {
          console.log(`âœ… ë¬¸ì„œ ì²˜ë¦¬ ì„±ê³µ: ${document.fileName} (ì‹œë„ ${attempt})`);
          return result;
        } else {
          lastError = result.error || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
          console.log(`âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: ${document.fileName} - ${lastError}`);
        }
      } catch (error) {
        lastError = error instanceof Error ? error.message : 'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ';
        console.log(`âš ï¸ ë¬¸ì„œ ì²˜ë¦¬ ì˜ˆì™¸: ${document.fileName} - ${lastError}`);
      }

      // ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„ ì „ ëŒ€ê¸°
      if (attempt <= maxRetries) {
        const backoffTime = Math.pow(2, attempt - 1) * 1000; // ì§€ìˆ˜ ë°±ì˜¤í”„
        await this.delay(backoffTime);
      }
    }

    return { success: false, error: lastError };
  }

  /**
   * ë¬¸ì„œ ë°°ì¹˜ ìƒì„±
   */
  private createBatches(documents: DocumentTask[], batchSize: number): DocumentTask[][] {
    const batches: DocumentTask[][] = [];

    for (let i = 0; i < documents.length; i += batchSize) {
      batches.push(documents.slice(i, i + batchSize));
    }

    return batches;
  }

  /**
   * ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
   */
  private calculatePerformanceMetrics(
    completedTasks: ProcessingResult['completedTasks'],
    totalTime: number,
    maxConcurrency: number
  ): ProcessingResult['performance'] {
    const throughput = completedTasks.length / (totalTime / 1000);

    const averageProcessingTime = completedTasks.length > 0
      ? completedTasks.reduce((sum, task) => sum + task.processingTime, 0) / completedTasks.length
      : 0;

    const theoreticalMaxTime = completedTasks.reduce((sum, task) => sum + task.processingTime, 0);
    const concurrencyUtilization = theoreticalMaxTime > 0
      ? Math.min(1.0, (theoreticalMaxTime / maxConcurrency) / totalTime)
      : 0;

    return {
      throughput,
      averageProcessingTime,
      concurrencyUtilization
    };
  }

  /**
   * í† í° ìˆ˜ ì¶”ì • (ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜)
   */
  public estimateTokens(content: string): number {
    // ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” tokenizer ì‚¬ìš© ê¶Œì¥)
    const words = content.split(/\s+/).length;
    const characters = content.length;

    // GPT ê³„ì—´: ëŒ€ëµ 1 í† í° = 4 ê¸€ì (ì˜ì–´ ê¸°ì¤€)
    // í•œêµ­ì–´ëŠ” ë” ë§ì€ í† í° ì‚¬ìš©
    const estimatedTokens = Math.ceil(characters / 3); // í•œêµ­ì–´ ê³ ë ¤

    return Math.max(words, estimatedTokens);
  }

  /**
   * ë¬¸ì„œ ìš°ì„ ìˆœìœ„ ìë™ ê³„ì‚°
   */
  public calculatePriority(document: { fileName: string; content: string }): number {
    const fileName = document.fileName.toLowerCase();
    const contentLength = document.content.length;

    // íŒŒì¼ëª… ê¸°ë°˜ ìš°ì„ ìˆœìœ„
    if (fileName.includes('readme') || fileName.includes('overview')) return 1;
    if (fileName.includes('plan') || fileName.includes('spec')) return 2;
    if (fileName.includes('requirement') || fileName.includes('needs')) return 2;
    if (fileName.includes('design') || fileName.includes('architecture')) return 3;
    if (fileName.includes('technical') || fileName.includes('detail')) return 3;

    // ë‚´ìš© ê¸¸ì´ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ (ì§§ì€ ë¬¸ì„œê°€ ìš°ì„ )
    if (contentLength < 1000) return 2;
    if (contentLength < 5000) return 3;
    if (contentLength < 10000) return 4;

    return 5; // ê¸°ë³¸ê°’
  }

  /**
   * ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ìœ„í•œ í° ë¬¸ì„œ ë¶„í• 
   */
  public splitLargeDocument(
    document: DocumentTask,
    maxChunkSize: number = 8000
  ): DocumentTask[] {
    if (document.content.length <= maxChunkSize) {
      return [document];
    }

    const chunks: DocumentTask[] = [];
    const content = document.content;
    const totalChunks = Math.ceil(content.length / maxChunkSize);

    for (let i = 0; i < totalChunks; i++) {
      const start = i * maxChunkSize;
      const end = Math.min(start + maxChunkSize, content.length);
      const chunkContent = content.slice(start, end);

      chunks.push({
        id: `${document.id}_chunk_${i + 1}`,
        fileName: `${document.fileName} (${i + 1}/${totalChunks})`,
        content: chunkContent,
        priority: document.priority,
        estimatedTokens: this.estimateTokens(chunkContent)
      });
    }

    console.log(`ğŸ“‘ í° ë¬¸ì„œ ë¶„í• : ${document.fileName} â†’ ${chunks.length}ê°œ ì²­í¬`);
    return chunks;
  }

  /**
   * ì²˜ë¦¬ ìƒíƒœ ëª¨ë‹ˆí„°ë§
   */
  public getProcessingStatus(): {
    activeJobs: number;
    queueLength: number;
    concurrencyLimit: number;
  } {
    return {
      activeJobs: this.activeJobs.size,
      queueLength: this.processingQueue.length,
      concurrencyLimit: this.concurrencyLimit
    };
  }

  /**
   * ìœ í‹¸ë¦¬í‹°: ì§€ì—° í•¨ìˆ˜
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * ë¦¬ì†ŒìŠ¤ ì •ë¦¬
   */
  public cleanup(): void {
    this.activeJobs.clear();
    this.processingQueue = [];
    console.log('ğŸ§¹ ParallelDocumentProcessor ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ');
  }
}