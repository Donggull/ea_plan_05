// AI ì„œë¹„ìŠ¤ í†µí•© ê´€ë¦¬ì
// ì—¬ëŸ¬ AI ì œê³µìë¥¼ í†µí•©í•˜ì—¬ ê´€ë¦¬í•˜ê³  í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•©ë‹ˆë‹¤.

import { AIModel } from '../../contexts/AIModelContext'
import { supabase } from '../../lib/supabase'

// AI ì œê³µì ì¶”ìƒ í´ë˜ìŠ¤
export abstract class AIProvider {
  abstract providerId: string
  abstract name: string
  abstract authenticate(apiKey: string): Promise<boolean>
  abstract generateCompletion(
    prompt: string,
    options: CompletionOptions
  ): Promise<CompletionResponse>
  abstract estimateTokens(text: string): number
  abstract getModels(): Promise<AIModel[]>
}

// ì™„ì„± ìš”ì²­ ì˜µì…˜
export interface CompletionOptions {
  model: string
  maxTokens?: number
  temperature?: number
  topP?: number
  frequencyPenalty?: number
  presencePenalty?: number
  stopSequences?: string[]
  stream?: boolean
}

// ì™„ì„± ì‘ë‹µ
export interface CompletionResponse {
  content: string
  usage: {
    inputTokens: number
    outputTokens: number
    totalTokens: number
  }
  cost: {
    inputCost: number
    outputCost: number
    totalCost: number
  }
  model: string
  finishReason: 'stop' | 'length' | 'content_filter' | 'error'
  responseTime: number
}

// í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
export interface TokenUsage {
  id?: string
  userId: string
  providerId: string
  modelId: string
  inputTokens: number
  outputTokens: number
  totalTokens: number
  inputCost: number
  outputCost: number
  totalCost: number
  timestamp: string
  requestType: 'completion' | 'analysis' | 'question_generation' | 'report_generation'
  sessionId?: string
  projectId?: string
}

// OpenAI ì œê³µì êµ¬í˜„
export class OpenAIProvider extends AIProvider {
  providerId = 'openai'
  name = 'OpenAI'
  private apiKey: string | null = null

  async authenticate(apiKey: string): Promise<boolean> {
    try {
      this.apiKey = apiKey
      // OpenAI API í‚¤ ê²€ì¦
      const response = await fetch('https://api.openai.com/v1/models', {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })
      return response.ok
    } catch (error) {
      console.error('OpenAI ì¸ì¦ ì‹¤íŒ¨:', error)
      return false
    }
  }

  async generateCompletion(prompt: string, options: CompletionOptions): Promise<CompletionResponse> {
    if (!this.apiKey) {
      throw new Error('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    const startTime = Date.now()

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: options.model,
          messages: [{ role: 'user', content: prompt }],
          max_tokens: options.maxTokens || 2000,
          temperature: options.temperature || 0.7,
          top_p: options.topP || 1,
          frequency_penalty: options.frequencyPenalty || 0,
          presence_penalty: options.presencePenalty || 0,
          stop: options.stopSequences
        })
      })

      if (!response.ok) {
        throw new Error(`OpenAI API ì˜¤ë¥˜: ${response.status}`)
      }

      const data = await response.json()
      const responseTime = Date.now() - startTime

      // ë¹„ìš© ê³„ì‚° (ëª¨ë¸ë³„ í† í° ê°€ê²©)
      const modelPricing = this.getModelPricing(options.model)
      const inputCost = (data.usage.prompt_tokens * modelPricing.inputCost) / 1000
      const outputCost = (data.usage.completion_tokens * modelPricing.outputCost) / 1000

      return {
        content: data.choices[0].message.content,
        usage: {
          inputTokens: data.usage.prompt_tokens,
          outputTokens: data.usage.completion_tokens,
          totalTokens: data.usage.total_tokens
        },
        cost: {
          inputCost,
          outputCost,
          totalCost: inputCost + outputCost
        },
        model: options.model,
        finishReason: data.choices[0].finish_reason,
        responseTime
      }
    } catch (error) {
      console.error('OpenAI ì™„ì„± ìƒì„± ì‹¤íŒ¨:', error)
      throw error
    }
  }

  estimateTokens(text: string): number {
    // GPT í† í¬ë‚˜ì´ì € ê·¼ì‚¬ì¹˜ (1í† í° â‰ˆ 4ê¸€ì)
    return Math.ceil(text.length / 4)
  }

  async getModels(): Promise<AIModel[]> {
    // OpenAI ëª¨ë¸ ëª©ë¡ ë°˜í™˜ (ì‹¤ì œë¡œëŠ” APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
    return [
      {
        id: 'openai-gpt-4o',
        name: 'GPT-4o',
        provider: 'openai',
        model_id: 'gpt-4o',
        cost_per_input_token: 0.005,
        cost_per_output_token: 0.015,
        status: 'active',
        capabilities: ['text', 'analysis', 'reasoning'],
        max_tokens: 128000,
        available: true
      },
      {
        id: 'openai-gpt-4o-mini',
        name: 'GPT-4o Mini',
        provider: 'openai',
        model_id: 'gpt-4o-mini',
        cost_per_input_token: 0.00015,
        cost_per_output_token: 0.0006,
        status: 'active',
        capabilities: ['text', 'analysis'],
        max_tokens: 128000,
        available: true
      }
    ]
  }

  private getModelPricing(model: string): { inputCost: number; outputCost: number } {
    const pricing: Record<string, { inputCost: number; outputCost: number }> = {
      'gpt-4o': { inputCost: 5, outputCost: 15 },
      'gpt-4o-mini': { inputCost: 0.15, outputCost: 0.6 },
      'gpt-4-turbo': { inputCost: 10, outputCost: 30 },
      'gpt-3.5-turbo': { inputCost: 0.5, outputCost: 1.5 }
    }
    return pricing[model] || { inputCost: 1, outputCost: 2 }
  }
}

// Anthropic ì œê³µì êµ¬í˜„
export class AnthropicProvider extends AIProvider {
  providerId = 'anthropic'
  name = 'Anthropic'
  private apiKey: string | null = null

  async authenticate(apiKey: string): Promise<boolean> {
    try {
      this.apiKey = apiKey
      // Anthropic API í‚¤ ê²€ì¦ì„ ìœ„í•œ ê°„ë‹¨í•œ ìš”ì²­
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
          model: 'claude-3-haiku-20240307',
          max_tokens: 10,
          messages: [{ role: 'user', content: 'test' }]
        })
      })
      return response.ok || response.status === 400 // 400ë„ ì¸ì¦ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    } catch (error) {
      console.error('Anthropic ì¸ì¦ ì‹¤íŒ¨:', error)
      return false
    }
  }

  async generateCompletion(prompt: string, options: CompletionOptions): Promise<CompletionResponse> {
    if (!this.apiKey) {
      throw new Error('Anthropic API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    const startTime = Date.now()

    try {
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'x-api-key': this.apiKey,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        },
        body: JSON.stringify({
          model: options.model,
          max_tokens: options.maxTokens || 2000,
          temperature: options.temperature || 0.7,
          top_p: options.topP || 1,
          messages: [{ role: 'user', content: prompt }],
          stop_sequences: options.stopSequences
        })
      })

      if (!response.ok) {
        throw new Error(`Anthropic API ì˜¤ë¥˜: ${response.status}`)
      }

      const data = await response.json()
      const responseTime = Date.now() - startTime

      // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì • (ì‹¤ì œ APIì—ì„œëŠ” ì œê³µí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
      const inputTokens = this.estimateTokens(prompt)
      const outputTokens = this.estimateTokens(data.content[0].text)

      // ë¹„ìš© ê³„ì‚°
      const modelPricing = this.getModelPricing(options.model)
      const inputCost = (inputTokens * modelPricing.inputCost) / 1000
      const outputCost = (outputTokens * modelPricing.outputCost) / 1000

      return {
        content: data.content[0].text,
        usage: {
          inputTokens,
          outputTokens,
          totalTokens: inputTokens + outputTokens
        },
        cost: {
          inputCost,
          outputCost,
          totalCost: inputCost + outputCost
        },
        model: options.model,
        finishReason: data.stop_reason || 'stop',
        responseTime
      }
    } catch (error) {
      console.error('Anthropic ì™„ì„± ìƒì„± ì‹¤íŒ¨:', error)
      throw error
    }
  }

  estimateTokens(text: string): number {
    // Claude í† í¬ë‚˜ì´ì € ê·¼ì‚¬ì¹˜ (1í† í° â‰ˆ 3.5ê¸€ì)
    return Math.ceil(text.length / 3.5)
  }

  async getModels(): Promise<AIModel[]> {
    return [
      {
        id: 'anthropic-claude-4-sonnet',
        name: 'Claude 4 Sonnet',
        provider: 'anthropic',
        model_id: 'claude-sonnet-4-20250514',
        cost_per_input_token: 0.003,
        cost_per_output_token: 0.015,
        status: 'active',
        capabilities: ['text', 'analysis', 'reasoning', 'coding', 'latest_generation'],
        max_tokens: 200000,
        available: true
      },
      {
        id: 'anthropic-claude-3-5-sonnet',
        name: 'Claude 3.5 Sonnet',
        provider: 'anthropic',
        model_id: 'claude-3-5-sonnet-20241022',
        cost_per_input_token: 0.003,
        cost_per_output_token: 0.015,
        status: 'active',
        capabilities: ['text', 'analysis', 'reasoning', 'coding'],
        max_tokens: 200000,
        available: true
      },
      {
        id: 'anthropic-claude-3-haiku',
        name: 'Claude 3 Haiku',
        provider: 'anthropic',
        model_id: 'claude-3-haiku-20240307',
        cost_per_input_token: 0.00025,
        cost_per_output_token: 0.00125,
        status: 'active',
        capabilities: ['text', 'analysis'],
        max_tokens: 200000,
        available: true
      }
    ]
  }

  private getModelPricing(model: string): { inputCost: number; outputCost: number } {
    const pricing: Record<string, { inputCost: number; outputCost: number }> = {
      'claude-sonnet-4-20250514': { inputCost: 3, outputCost: 15 },
      'claude-3-5-sonnet-20241022': { inputCost: 3, outputCost: 15 },
      'claude-3-opus-20240229': { inputCost: 15, outputCost: 75 },
      'claude-3-haiku-20240307': { inputCost: 0.25, outputCost: 1.25 }
    }
    return pricing[model] || { inputCost: 1, outputCost: 5 }
  }
}

// Google AI ì œê³µì êµ¬í˜„
export class GoogleAIProvider extends AIProvider {
  providerId = 'google'
  name = 'Google AI'
  private apiKey: string | null = null

  async authenticate(apiKey: string): Promise<boolean> {
    try {
      this.apiKey = apiKey
      // Google AI API í‚¤ ê²€ì¦
      const response = await fetch(`https://generativelanguage.googleapis.com/v1/models?key=${apiKey}`)
      return response.ok
    } catch (error) {
      console.error('Google AI ì¸ì¦ ì‹¤íŒ¨:', error)
      return false
    }
  }

  async generateCompletion(prompt: string, options: CompletionOptions): Promise<CompletionResponse> {
    if (!this.apiKey) {
      throw new Error('Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    const startTime = Date.now()

    try {
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1/models/${options.model}:generateContent?key=${this.apiKey}`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents: [{ parts: [{ text: prompt }] }],
            generationConfig: {
              maxOutputTokens: options.maxTokens || 2000,
              temperature: options.temperature || 0.7,
              topP: options.topP || 1,
              stopSequences: options.stopSequences
            }
          })
        }
      )

      if (!response.ok) {
        throw new Error(`Google AI API ì˜¤ë¥˜: ${response.status}`)
      }

      const data = await response.json()
      const responseTime = Date.now() - startTime

      // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì •
      const inputTokens = this.estimateTokens(prompt)
      const outputTokens = this.estimateTokens(data.candidates[0].content.parts[0].text)

      // ë¹„ìš© ê³„ì‚°
      const modelPricing = this.getModelPricing(options.model)
      const inputCost = (inputTokens * modelPricing.inputCost) / 1000
      const outputCost = (outputTokens * modelPricing.outputCost) / 1000

      return {
        content: data.candidates[0].content.parts[0].text,
        usage: {
          inputTokens,
          outputTokens,
          totalTokens: inputTokens + outputTokens
        },
        cost: {
          inputCost,
          outputCost,
          totalCost: inputCost + outputCost
        },
        model: options.model,
        finishReason: data.candidates[0].finishReason?.toLowerCase() || 'stop',
        responseTime
      }
    } catch (error) {
      console.error('Google AI ì™„ì„± ìƒì„± ì‹¤íŒ¨:', error)
      throw error
    }
  }

  estimateTokens(text: string): number {
    // Gemini í† í¬ë‚˜ì´ì € ê·¼ì‚¬ì¹˜ (1í† í° â‰ˆ 4ê¸€ì)
    return Math.ceil(text.length / 4)
  }

  async getModels(): Promise<AIModel[]> {
    return [
      {
        id: 'google-gemini-2-0-flash',
        name: 'Gemini 2.0 Flash',
        provider: 'google',
        model_id: 'gemini-2.0-flash-exp',
        cost_per_input_token: 0.000075,
        cost_per_output_token: 0.0003,
        status: 'active',
        capabilities: ['text', 'analysis', 'reasoning', 'multimodal'],
        max_tokens: 1000000,
        available: true
      },
      {
        id: 'google-gemini-1-5-pro',
        name: 'Gemini 1.5 Pro',
        provider: 'google',
        model_id: 'gemini-1.5-pro',
        cost_per_input_token: 0.00125,
        cost_per_output_token: 0.005,
        status: 'active',
        capabilities: ['text', 'analysis', 'reasoning', 'multimodal'],
        max_tokens: 2000000,
        available: true
      }
    ]
  }

  private getModelPricing(model: string): { inputCost: number; outputCost: number } {
    const pricing: Record<string, { inputCost: number; outputCost: number }> = {
      'gemini-2.0-flash-exp': { inputCost: 0.075, outputCost: 0.3 },
      'gemini-1.5-pro': { inputCost: 1.25, outputCost: 5 },
      'gemini-1.5-flash': { inputCost: 0.075, outputCost: 0.3 }
    }
    return pricing[model] || { inputCost: 1, outputCost: 2 }
  }
}

// AI ì„œë¹„ìŠ¤ ë§¤ë‹ˆì € (ë©”ì¸ í´ë˜ìŠ¤)
export class AIServiceManager {
  private static instance: AIServiceManager
  private providers: Map<string, AIProvider> = new Map()
  private currentProvider: AIProvider | null = null

  private constructor() {
    // ê¸°ë³¸ ì œê³µìë“¤ ë“±ë¡
    this.providers.set('openai', new OpenAIProvider())
    this.providers.set('anthropic', new AnthropicProvider())
    this.providers.set('google', new GoogleAIProvider())
  }

  static getInstance(): AIServiceManager {
    if (!AIServiceManager.instance) {
      AIServiceManager.instance = new AIServiceManager()
    }
    return AIServiceManager.instance
  }

  // ì œê³µì ì„¤ì • ë° ì¸ì¦
  async setProvider(providerId: string, apiKey: string): Promise<boolean> {
    const provider = this.providers.get(providerId)
    if (!provider) {
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” AI ì œê³µì: ${providerId}`)
    }

    const authenticated = await provider.authenticate(apiKey)
    if (authenticated) {
      this.currentProvider = provider
      return true
    }
    return false
  }

  // í˜„ì¬ ì œê³µì ê°€ì ¸ì˜¤ê¸°
  getCurrentProvider(): AIProvider | null {
    return this.currentProvider
  }

  // ì‚¬ìš© ê°€ëŠ¥í•œ ì œê³µì ëª©ë¡
  getAvailableProviders(): string[] {
    return Array.from(this.providers.keys())
  }

  // AI ì™„ì„± ìƒì„± (í† í° ì‚¬ìš©ëŸ‰ ìë™ ì¶”ì )
  async generateCompletion(
    prompt: string,
    options: CompletionOptions,
    context?: {
      userId?: string
      sessionId?: string
      projectId?: string
      requestType?: TokenUsage['requestType']
    }
  ): Promise<CompletionResponse> {
    if (!this.currentProvider) {
      throw new Error('AI ì œê³µìê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    }

    const result = await this.currentProvider.generateCompletion(prompt, options)

    // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
    if (context?.userId) {
      await this.trackTokenUsage({
        userId: context.userId,
        providerId: this.currentProvider.providerId,
        modelId: options.model,
        inputTokens: result.usage.inputTokens,
        outputTokens: result.usage.outputTokens,
        totalTokens: result.usage.totalTokens,
        inputCost: result.cost.inputCost,
        outputCost: result.cost.outputCost,
        totalCost: result.cost.totalCost,
        timestamp: new Date().toISOString(),
        requestType: context.requestType || 'completion',
        sessionId: context.sessionId,
        projectId: context.projectId
      })
    }

    return result
  }

  // í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
  async trackTokenUsage(usage: TokenUsage): Promise<void> {
    try {
      if (!supabase) return

      // user_api_usage í…Œì´ë¸”ì— ì‚¬ìš©ëŸ‰ ê¸°ë¡
      const currentDate = new Date().toISOString().split('T')[0] // YYYY-MM-DD í˜•ì‹
      const { error } = await supabase
        .from('user_api_usage')
        .insert({
          user_id: usage.userId,
          model: usage.modelId,
          input_tokens: usage.inputTokens,
          output_tokens: usage.outputTokens,
          total_tokens: usage.totalTokens,
          cost: usage.totalCost,
          date: currentDate
        })

      if (error) {
        console.error('í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ì‹¤íŒ¨:', error)
      }
    } catch (error) {
      console.error('í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ì¤‘ ì˜¤ë¥˜:', error)
    }
  }

  // ì‚¬ìš©ìë³„ í† í° ì‚¬ìš© í†µê³„
  async getUserUsageStats(userId: string, timeframe: 'day' | 'week' | 'month' = 'month'): Promise<{
    totalTokens: number
    totalCost: number
    requestCount: number
    topModels: Array<{ model: string; usage: number }>
  }> {
    try {
      if (!supabase) {
        return { totalTokens: 0, totalCost: 0, requestCount: 0, topModels: [] }
      }

      const now = new Date()
      let startDate: Date

      switch (timeframe) {
        case 'day':
          startDate = new Date(now.getTime() - 24 * 60 * 60 * 1000)
          break
        case 'week':
          startDate = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000)
          break
        case 'month':
          startDate = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000)
          break
      }

      const { data, error } = await supabase
        .from('user_api_usage')
        .select('*')
        .eq('user_id', userId)
        .gte('created_at', startDate.toISOString())

      if (error) {
        console.error('ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨:', error)
        return { totalTokens: 0, totalCost: 0, requestCount: 0, topModels: [] }
      }

      const totalTokens = data?.reduce((sum, record) => sum + (record.total_tokens || 0), 0) || 0
      const totalCost = data?.reduce((sum, record) => sum + (record.cost || 0), 0) || 0
      const requestCount = data?.length || 0

      // ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ í†µê³„
      const modelUsage = data?.reduce((acc, record) => {
        const model = record.model || 'unknown'
        acc[model] = (acc[model] || 0) + (record.total_tokens || 0)
        return acc
      }, {} as Record<string, number>) || {}

      const topModels = Object.entries(modelUsage)
        .sort(([, a], [, b]) => b - a)
        .slice(0, 5)
        .map(([model, usage]) => ({ model, usage }))

      return { totalTokens, totalCost, requestCount, topModels }
    } catch (error) {
      console.error('ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜:', error)
      return { totalTokens: 0, totalCost: 0, requestCount: 0, topModels: [] }
    }
  }

  // ëª¨ë“  ì œê³µìì˜ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
  async getAllModels(): Promise<AIModel[]> {
    const allModels: AIModel[] = []

    for (const provider of this.providers.values()) {
      try {
        const models = await provider.getModels()
        allModels.push(...models)
      } catch (error) {
        console.error(`${provider.name} ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨:`, error)
      }
    }

    return allModels
  }

  // ëª¨ë¸ ì¶”ì²œ (ìš©ë„ë³„)
  getRecommendedModels(models: AIModel[]) {
    const availableModels = models.filter(model => model.available)

    return {
      fastest: availableModels.reduce((prev, current) =>
        (prev.cost_per_input_token < current.cost_per_input_token) ? prev : current
      ),
      cheapest: availableModels.reduce((prev, current) =>
        (prev.cost_per_input_token + prev.cost_per_output_token) <
        (current.cost_per_input_token + current.cost_per_output_token) ? prev : current
      ),
      best_performance: availableModels.find(model =>
        model.capabilities.includes('reasoning') && model.max_tokens > 100000
      ) || availableModels[0],
      balanced: availableModels.find(model =>
        model.cost_per_input_token < 0.005 && model.max_tokens > 50000
      ) || availableModels[0]
    }
  }
}

// AIServiceManager ìë™ ì´ˆê¸°í™” í•¨ìˆ˜
export async function initializeAIServiceManager(): Promise<void> {
  console.log('ğŸ¤– AIServiceManager ì´ˆê¸°í™” ì¤‘...')

  // í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸° (VITE_ ì ‘ë‘ì‚¬ ì œê±°ë¨)
  const anthropicApiKey = import.meta.env['ANTHROPIC_API_KEY']
  const openaiApiKey = import.meta.env['OPENAI_API_KEY']
  const googleApiKey = import.meta.env['GOOGLE_AI_API_KEY']

  console.log('ğŸ”‘ API í‚¤ í™•ì¸:')
  console.log('- Anthropic:', anthropicApiKey ? 'âœ… ì„¤ì •ë¨' : 'âŒ ëˆ„ë½')
  console.log('- OpenAI:', openaiApiKey ? 'âœ… ì„¤ì •ë¨' : 'âŒ ëˆ„ë½')
  console.log('- Google AI:', googleApiKey ? 'âœ… ì„¤ì •ë¨' : 'âŒ ëˆ„ë½')

  const manager = aiServiceManager

  // ìš°ì„ ìˆœìœ„: Anthropic > OpenAI > Google AI
  let initialized = false

  // Anthropic API í‚¤ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
  if (anthropicApiKey && anthropicApiKey !== 'your-anthropic-key-here') {
    try {
      const success = await manager.setProvider('anthropic', anthropicApiKey)
      if (success) {
        console.log('âœ… Anthropic ì œê³µìê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
        initialized = true
      } else {
        console.warn('âš ï¸ Anthropic ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
      }
    } catch (error) {
      console.error('âŒ Anthropic ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
    }
  }

  // Anthropic ì‹¤íŒ¨ ì‹œ OpenAI ì‹œë„
  if (!initialized && openaiApiKey && openaiApiKey !== 'sk-your-openai-key-here') {
    try {
      const success = await manager.setProvider('openai', openaiApiKey)
      if (success) {
        console.log('âœ… OpenAI ì œê³µìê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
        initialized = true
      } else {
        console.warn('âš ï¸ OpenAI ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
      }
    } catch (error) {
      console.error('âŒ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
    }
  }

  // OpenAI ì‹¤íŒ¨ ì‹œ Google AI ì‹œë„
  if (!initialized && googleApiKey && googleApiKey !== 'your-google-ai-key-here') {
    try {
      const success = await manager.setProvider('google', googleApiKey)
      if (success) {
        console.log('âœ… Google AI ì œê³µìê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.')
        initialized = true
      } else {
        console.warn('âš ï¸ Google AI ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.')
      }
    } catch (error) {
      console.error('âŒ Google AI ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
    }
  }

  if (!initialized) {
    console.error('âŒ ì‚¬ìš© ê°€ëŠ¥í•œ AI ì œê³µìê°€ ì—†ìŠµë‹ˆë‹¤.')
    console.error('ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì„¤ì •í•´ì£¼ì„¸ìš”:')
    console.error('- ANTHROPIC_API_KEY: Anthropic API í‚¤')
    console.error('- OPENAI_API_KEY: OpenAI API í‚¤')
    console.error('- GOOGLE_AI_API_KEY: Google AI API í‚¤')
  } else {
    const currentProvider = manager.getCurrentProvider()
    console.log(`ğŸ¯ í˜„ì¬ í™œì„± ì œê³µì: ${currentProvider?.name || 'ì—†ìŒ'}`)
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë‚´ë³´ë‚´ê¸°
export const aiServiceManager = AIServiceManager.getInstance()