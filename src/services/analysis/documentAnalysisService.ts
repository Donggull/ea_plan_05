import { supabase } from '../../lib/supabase'
import { AIProviderFactory, AIMessage, AIResponse } from '../ai/providerFactory'
import { ApiUsageService } from '../apiUsageService'

import {
  DocumentAnalysisContext,
  DocumentAnalysisResult,
  IntegratedAnalysisResult,
  WorkflowStep,
  ProjectAnalysisStatus
} from '../../types/documentAnalysis'

// ë¬¸ì„œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
const DOCUMENT_ANALYSIS_PROMPTS = {
  comprehensive: {
    system: `ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì´ì í”„ë¡œì íŠ¸ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ì˜ ì‹œì¥ì¡°ì‚¬, í˜ë¥´ì†Œë‚˜ ë¶„ì„, ì œì•ˆì„œ ì‘ì„±, ê²¬ì  ì‚°ì¶œì— ë„ì›€ì´ ë˜ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë¶„ì„ ëª©í‘œ:
1. ë¬¸ì„œì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ê³¼ ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ ì‹ë³„
2. ì‹œì¥ ê´€ë ¨ ì •ë³´ì™€ ê²½ìŸì‚¬ ì •ë³´ ì¶”ì¶œ
3. íƒ€ê²Ÿ ê³ ê°ê³¼ í˜ë¥´ì†Œë‚˜ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
4. í”„ë¡œì íŠ¸ ë²”ìœ„, ì¼ì •, ì˜ˆì‚° ê´€ë ¨ ì •ë³´ íŒŒì•…
5. ê° ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ë°ì´í„° ë¶„ë¥˜

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
{
  "summary": "ë¬¸ì„œ ë‚´ìš© ìš”ì•½ (2-3ë¬¸ì¥)",
  "keyInsights": ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1", "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2", ...],
  "relevantWorkflowSteps": ["market_research", "personas", "proposal", "budget"],
  "extractedData": {
    "businessRequirements": ["ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ë“¤"],
    "technicalSpecs": ["ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ë“¤"],
    "marketInsights": ["ì‹œì¥ ê´€ë ¨ ì •ë³´ë“¤"],
    "budgetInfo": {
      "estimatedCost": "ì˜ˆìƒ ë¹„ìš©",
      "currency": "í†µí™”",
      "breakdown": ["ë¹„ìš© êµ¬ì„± ìš”ì†Œë“¤"]
    },
    "timeline": "í”„ë¡œì íŠ¸ ì¼ì • ê´€ë ¨ ì •ë³´",
    "stakeholders": ["ì´í•´ê´€ê³„ìë“¤"]
  },
  "recommendations": ["ì´ ë¬¸ì„œë¥¼ í™œìš©í•œ ê¶Œì¥ì‚¬í•­ë“¤"],
  "confidence": 0.85
}`,

    user: `í”„ë¡œì íŠ¸ëª…: {projectName}
í”„ë¡œì íŠ¸ ì„¤ëª…: {projectDescription}

=== ë¶„ì„í•  ë¬¸ì„œ ===
íŒŒì¼ëª…: {fileName}
íŒŒì¼ ìœ í˜•: {fileType}

ë¬¸ì„œ ë‚´ìš©:
{documentContent}

ì´ ë¬¸ì„œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ì˜ ì‹œì¥ì¡°ì‚¬, í˜ë¥´ì†Œë‚˜ ë¶„ì„, ì œì•ˆì„œ ì‘ì„±, ê²¬ì  ì‚°ì¶œì— í™œìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë“  ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.`
  },

  workflow_integration: {
    system: `ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì›Œí¬í”Œë¡œìš° ë‹¨ê³„(ì‹œì¥ì¡°ì‚¬, í˜ë¥´ì†Œë‚˜, ì œì•ˆì„œ, ê²¬ì )ì˜ ì¤€ë¹„ ìƒíƒœë¥¼ í‰ê°€í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
- ê° ë‹¨ê³„ë³„ í•„ìˆ˜ ë°ì´í„°ì˜ ì¶©ì¡±ë„
- ì¶”ê°€ë¡œ í•„ìš”í•œ ì§ˆë¬¸ë“¤
- ë°ì´í„° í’ˆì§ˆê³¼ ì‹ ë¢°ë„
- ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ì„ ìœ„í•œ ì¤€ë¹„ë„

ì‘ë‹µ í˜•ì‹:
{
  "overallSummary": "ì „ì²´ ë¬¸ì„œ ë¶„ì„ ìš”ì•½",
  "workflowRecommendations": {
    "market_research": {
      "readiness": 0.8,
      "suggestedQuestions": ["ì¶”ê°€ í•„ìš”í•œ ì§ˆë¬¸ë“¤"],
      "dataGaps": ["ë¶€ì¡±í•œ ë°ì´í„°ë“¤"],
      "confidence": 0.85
    },
    "personas": { ... },
    "proposal": { ... },
    "budget": { ... }
  },
  "nextSteps": ["ê¶Œì¥ ë‹¤ìŒ ë‹¨ê³„ë“¤"],
  "priorityActions": ["ìš°ì„ ìˆœìœ„ ì•¡ì…˜ ì•„ì´í…œë“¤"]
}`,

    user: `í”„ë¡œì íŠ¸: {projectName}

=== ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ë“¤ ===
{documentAnalysisResults}

=== ê¸°ì¡´ ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒí™© ===
{workflowStatus}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ì˜ ì¤€ë¹„ ìƒíƒœë¥¼ í‰ê°€í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.`
  }
}

/**
 * ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤
 * í”„ë¡œì íŠ¸ ë¬¸ì„œë“¤ì„ AIë¡œ ë¶„ì„í•˜ì—¬ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ì¸ì‚¬ì´íŠ¸ ì œê³µ
 */
export class DocumentAnalysisService {
  /**
   * í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì¢…í•© ë¶„ì„
   */
  static async analyzeProjectDocuments(
    projectId: string,
    userId: string,
    options: {
      modelId?: string
      targetSteps?: WorkflowStep[]
      forceReanalysis?: boolean
      documentIds?: string[] // íŠ¹ì • ë¬¸ì„œë§Œ ë¶„ì„í•˜ëŠ” ì˜µì…˜ ì¶”ê°€
    } = {}
  ): Promise<IntegratedAnalysisResult> {
    const startTime = Date.now()
    let totalCost = 0
    let totalTokens = 0
    let modelUsed = ''

    try {
      // 1. í”„ë¡œì íŠ¸ ì •ë³´ ë° ë¬¸ì„œ ì¡°íšŒ
      const context = await this.prepareAnalysisContext(projectId, options.targetSteps)

      // 2. ê° ë¬¸ì„œë³„ ê°œë³„ ë¶„ì„
      const documentAnalysisResults: DocumentAnalysisResult[] = []

      // íŠ¹ì • ë¬¸ì„œë“¤ë§Œ ë¶„ì„í•˜ëŠ” ê²½ìš° í•„í„°ë§
      const documentsToAnalyze = options.documentIds
        ? context.documents.filter(doc => options.documentIds!.includes(doc.id))
        : context.documents

      console.log(`ğŸ“Š ë¶„ì„ ëŒ€ìƒ ë¬¸ì„œ: ${documentsToAnalyze.length}ê°œ (ì „ì²´: ${context.documents.length}ê°œ)`)

      for (const document of documentsToAnalyze) {
        // ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ (forceReanalysisê°€ falseì¸ ê²½ìš°)
        if (!options.forceReanalysis) {
          const existingAnalysis = await this.getExistingDocumentAnalysis(document.id)
          if (existingAnalysis) {
            documentAnalysisResults.push(existingAnalysis)
            continue
          }
        }

        const docResult = await this.analyzeDocument(document, context, userId, options.modelId)
        documentAnalysisResults.push(docResult)

        totalCost += docResult.costSummary?.cost || 0
        totalTokens += docResult.costSummary?.tokens || 0
        modelUsed = docResult.costSummary?.model || modelUsed
      }

      // 3. í†µí•© ë¶„ì„ ë° ì›Œí¬í”Œë¡œìš° í‰ê°€
      const workflowRecommendations = await this.generateWorkflowRecommendations(
        context,
        documentAnalysisResults,
        userId,
        options.modelId
      )

      totalCost += workflowRecommendations.costSummary?.cost || 0
      totalTokens += workflowRecommendations.costSummary?.tokens || 0

      // 4. ê²°ê³¼ ì •ë¦¬
      const result: IntegratedAnalysisResult = {
        projectId,
        overallSummary: workflowRecommendations.overallSummary,
        documentInsights: documentAnalysisResults,
        workflowRecommendations: workflowRecommendations.recommendations,
        nextSteps: workflowRecommendations.nextSteps,
        totalProcessingTime: Date.now() - startTime,
        costSummary: {
          totalCost,
          tokenUsage: totalTokens,
          modelUsed
        }
      }

      // 5. ê²°ê³¼ ì €ì¥
      await this.saveIntegratedAnalysisResult(result, userId)

      return result

    } catch (error) {
      console.error('ğŸ“Š ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨:', {
        projectId,
        userId,
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      })

      // ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ë³€í™˜
      const userFriendlyMessage = error instanceof Error
        ? error.message
        : 'ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'

      throw new Error(userFriendlyMessage)
    }
  }

  /**
   * ê°œë³„ ë¬¸ì„œ ë¶„ì„
   */
  private static async analyzeDocument(
    document: any,
    context: DocumentAnalysisContext,
    userId: string,
    modelId?: string
  ): Promise<DocumentAnalysisResult> {
    const startTime = Date.now()

    try {
      // AI ëª¨ë¸ ì„ íƒ
      const selectedModel = await this.selectAIModel(context.projectId, userId, modelId)
      console.log(`ğŸ“Š ì„ íƒëœ ëª¨ë¸:`, { selectedModel, originalModelId: modelId })

      // í”„ë¡¬í”„íŠ¸ ìƒì„±
      const prompt = this.generateDocumentAnalysisPrompt(document, context)

      // AI ë¶„ì„ ì‹¤í–‰
      const aiResponse = await this.executeAIAnalysis(selectedModel, prompt, userId)

      // ê²°ê³¼ íŒŒì‹±
      const analysisData = this.parseDocumentAnalysisResult(aiResponse.content)

      const result: DocumentAnalysisResult = {
        documentId: document.id,
        fileName: document.file_name,
        summary: analysisData.summary,
        keyInsights: analysisData.keyInsights,
        relevantWorkflowSteps: analysisData.relevantWorkflowSteps,
        extractedData: analysisData.extractedData,
        recommendations: analysisData.recommendations,
        confidence: analysisData.confidence,
        processingTime: Date.now() - startTime,
        costSummary: {
          cost: aiResponse.cost,
          tokens: aiResponse.usage.input_tokens + aiResponse.usage.output_tokens,
          model: selectedModel
        }
      }

      // ê°œë³„ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥
      await this.saveDocumentAnalysisResult(result, selectedModel, aiResponse, userId)

      return result

    } catch (error) {
      console.error(`ğŸ“„ ê°œë³„ ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨ (${document.file_name}):`, {
        documentId: document.id,
        fileName: document.file_name,
        error: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      })

      // ì‚¬ìš©ì ì¹œí™”ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¡œ ë³€í™˜
      const userFriendlyMessage = error instanceof Error
        ? `ë¬¸ì„œ "${document.file_name}" ë¶„ì„ ì‹¤íŒ¨: ${error.message}`
        : `ë¬¸ì„œ "${document.file_name}" ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.`

      throw new Error(userFriendlyMessage)
    }
  }

  /**
   * ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
   */
  private static async prepareAnalysisContext(
    projectId: string,
    targetSteps?: WorkflowStep[]
  ): Promise<DocumentAnalysisContext> {
    // í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ
    const { data: projectInfo, error: projectError } = await supabase!
      .from('projects')
      .select('name, description, project_types, client_info')
      .eq('id', projectId)
      .single()

    if (projectError) throw projectError

    // ë¬¸ì„œ ì¡°íšŒ (content í¬í•¨)
    const { data: documents, error: documentsError } = await supabase!
      .from('documents')
      .select(`
        id,
        file_name,
        file_type,
        metadata,
        document_content:document_content(
          raw_text,
          processed_text,
          ocr_text
        )
      `)
      .eq('project_id', projectId)
      .eq('is_processed', true)

    if (documentsError) throw documentsError

    // ë¬¸ì„œ ë‚´ìš© ì •ë¦¬
    const documentsWithContent = documents?.map(doc => ({
      id: doc.id,
      file_name: doc.file_name,
      file_type: doc.file_type || 'unknown',
      metadata: doc.metadata || {},
      content: doc.document_content?.[0]?.processed_text ||
               doc.document_content?.[0]?.ocr_text ||
               doc.document_content?.[0]?.raw_text ||
               'ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
    })) || []

    return {
      projectId,
      projectInfo: {
        name: projectInfo.name,
        description: projectInfo.description || '',
        project_types: projectInfo.project_types || [],
        client_info: projectInfo.client_info
      },
      documents: documentsWithContent,
      targetWorkflowSteps: targetSteps || ['market_research', 'personas', 'proposal', 'budget']
    }
  }

  /**
   * ë¬¸ì„œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
   */
  private static generateDocumentAnalysisPrompt(
    document: any,
    context: DocumentAnalysisContext
  ): AIMessage[] {
    const template = DOCUMENT_ANALYSIS_PROMPTS.comprehensive

    const userPrompt = template.user
      .replace('{projectName}', context.projectInfo.name)
      .replace('{projectDescription}', context.projectInfo.description || 'ì„¤ëª… ì—†ìŒ')
      .replace('{fileName}', document.file_name)
      .replace('{fileType}', document.file_type)
      .replace('{documentContent}', document.content)

    return [
      { role: 'system', content: template.system },
      { role: 'user', content: userPrompt }
    ]
  }

  /**
   * ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ ìƒì„±
   */
  private static async generateWorkflowRecommendations(
    context: DocumentAnalysisContext,
    documentResults: DocumentAnalysisResult[],
    userId: string,
    modelId?: string
  ): Promise<{
    overallSummary: string
    recommendations: Record<WorkflowStep, any>
    nextSteps: string[]
    costSummary: { cost: number, tokens: number, model: string }
  }> {
    try {
      // í˜„ì¬ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ
      const workflowStatus = await this.getWorkflowStatus(context.projectId)

      // AI ëª¨ë¸ ì„ íƒ
      const selectedModel = await this.selectAIModel(context.projectId, userId, modelId)

      // í”„ë¡¬í”„íŠ¸ ìƒì„±
      const template = DOCUMENT_ANALYSIS_PROMPTS.workflow_integration
      const userPrompt = template.user
        .replace('{projectName}', context.projectInfo.name)
        .replace('{documentAnalysisResults}', JSON.stringify(documentResults, null, 2))
        .replace('{workflowStatus}', JSON.stringify(workflowStatus, null, 2))

      const prompt = [
        { role: 'system' as const, content: template.system },
        { role: 'user' as const, content: userPrompt }
      ]

      // AI ë¶„ì„ ì‹¤í–‰
      const aiResponse = await this.executeAIAnalysis(selectedModel, prompt, userId)

      // ê²°ê³¼ íŒŒì‹±
      const result = this.parseWorkflowRecommendationsResult(aiResponse.content)

      return {
        overallSummary: result.overallSummary,
        recommendations: result.workflowRecommendations,
        nextSteps: result.nextSteps,
        costSummary: {
          cost: aiResponse.cost,
          tokens: aiResponse.usage.input_tokens + aiResponse.usage.output_tokens,
          model: selectedModel
        }
      }

    } catch (error) {
      console.error('Workflow recommendations generation failed:', error)
      throw error
    }
  }

  /**
   * AI ëª¨ë¸ ì„ íƒ
   */
  private static async selectAIModel(
    projectId: string,
    userId: string,
    preferredModelId?: string
  ): Promise<string> {
    try {
      console.log(`ğŸ¯ AI ëª¨ë¸ ì„ íƒ ì‹œì‘:`, { projectId, userId, preferredModelId })

      // ë“±ë¡ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
      const availableModels = AIProviderFactory.getRegisteredModels()
      const availableModelIds = new Set(availableModels.map(m => m.id))
      const providerModelIdMap = new Map<string, string>()

      availableModels.forEach(model => {
        providerModelIdMap.set(model.model_id, model.id)
        providerModelIdMap.set(model.id, model.id)
      })

      console.log(`ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ${Array.from(availableModelIds).join(', ')}`)

      if (availableModelIds.size === 0) {
        throw new Error('ë“±ë¡ëœ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. AI Provider Factoryê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
      }

      const resolutionCache = new Map<string, string | null>()

      const resolveModelId = async (identifier?: string | null): Promise<string | null> => {
        if (!identifier) return null

        if (resolutionCache.has(identifier)) {
          return resolutionCache.get(identifier) ?? null
        }

        if (availableModelIds.has(identifier)) {
          resolutionCache.set(identifier, identifier)
          return identifier
        }

        const mappedByProviderId = providerModelIdMap.get(identifier)
        if (mappedByProviderId) {
          resolutionCache.set(identifier, mappedByProviderId)
          return mappedByProviderId
        }

        try {
          const { data, error } = await supabase!
            .from('ai_models')
            .select('model_id, metadata')
            .eq('id', identifier)
            .single()

          if (error) {
            if (error.code !== 'PGRST116') {
              console.warn('AI ëª¨ë¸ ì‹ë³„ì ì¡°íšŒ ì‹¤íŒ¨:', error)
            }
          }

          if (data) {
            const candidates: string[] = []

            if (typeof data.model_id === 'string') {
              candidates.push(data.model_id)
            }

            const metadata = (data.metadata || {}) as Record<string, unknown>
            const metadataKeys = [
              'registry_model_id',
              'registryModelId',
              'factory_model_id',
              'factoryModelId',
              'provider_model_id',
              'providerModelId',
              'model_key',
              'modelKey',
              'modelId',
              'id'
            ]

            const metadataCandidates = metadataKeys
              .map(key => metadata[key])
              .filter((value): value is string => typeof value === 'string' && value.length > 0)

            candidates.push(...metadataCandidates)

            for (const candidate of candidates) {
              if (availableModelIds.has(candidate)) {
                resolutionCache.set(identifier, candidate)
                return candidate
              }

              const mapped = providerModelIdMap.get(candidate)
              if (mapped) {
                resolutionCache.set(identifier, mapped)
                return mapped
              }
            }
          }
        } catch (dbError) {
          console.warn('AI ëª¨ë¸ ID ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', dbError)
        }

        resolutionCache.set(identifier, null)
        return null
      }

      // 1. ëª…ì‹œì ìœ¼ë¡œ ì œê³µëœ ëª¨ë¸ ID í™•ì¸
      const resolvedPreferred = await resolveModelId(preferredModelId)
      if (resolvedPreferred) {
        console.log(`âœ… ì§€ì •ëœ ëª¨ë¸ ì„ íƒ: ${resolvedPreferred} (ì›ë³¸ ID: ${preferredModelId})`)
        return resolvedPreferred
      }

      if (preferredModelId) {
        console.warn(`âš ï¸ ì§€ì •ëœ ëª¨ë¸(${preferredModelId})ì„ ë“±ë¡ëœ ëª¨ë¸ê³¼ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤.`)
      }

      // 2. í”„ë¡œì íŠ¸ë³„ ì„¤ì • í™•ì¸
      const { data: projectSettings } = await supabase!
        .from('project_ai_settings')
        .select('default_model_id, analysis_model_mappings')
        .eq('project_id', projectId)
        .single()

      if (projectSettings?.analysis_model_mappings &&
          typeof projectSettings.analysis_model_mappings === 'object' &&
          'document_analysis' in projectSettings.analysis_model_mappings) {
        const analysisMappings = projectSettings.analysis_model_mappings as Record<string, unknown>
        const mappedModel = analysisMappings['document_analysis'] as string | undefined
        const resolvedMapped = await resolveModelId(mappedModel)
        if (resolvedMapped) {
          console.log(`âœ… í”„ë¡œì íŠ¸ ë§¤í•‘ ëª¨ë¸ ì„ íƒ: ${resolvedMapped}`)
          return resolvedMapped
        }
        if (mappedModel) {
          console.warn(`âš ï¸ í”„ë¡œì íŠ¸ ë§¤í•‘ ëª¨ë¸(${mappedModel})ì„ ë“±ë¡ëœ ëª¨ë¸ê³¼ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`)
        }
      }

      if (projectSettings?.default_model_id) {
        const resolvedDefault = await resolveModelId(projectSettings.default_model_id)
        if (resolvedDefault) {
          console.log(`âœ… í”„ë¡œì íŠ¸ ê¸°ë³¸ ëª¨ë¸ ì„ íƒ: ${resolvedDefault}`)
          return resolvedDefault
        }
        console.warn(`âš ï¸ í”„ë¡œì íŠ¸ ê¸°ë³¸ ëª¨ë¸(${projectSettings.default_model_id})ì„ ë“±ë¡ëœ ëª¨ë¸ê³¼ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`)
      }

      // 3. ì‚¬ìš©ìë³„ ì„¤ì • í™•ì¸
      const { data: userSettings } = await supabase!
        .from('user_ai_settings')
        .select('preferred_model_id')
        .eq('user_id', userId)
        .single()

      if (userSettings?.preferred_model_id) {
        const resolvedUserModel = await resolveModelId(userSettings.preferred_model_id)
        if (resolvedUserModel) {
          console.log(`âœ… ì‚¬ìš©ì ì„ í˜¸ ëª¨ë¸ ì„ íƒ: ${resolvedUserModel}`)
          return resolvedUserModel
        }
        console.warn(`âš ï¸ ì‚¬ìš©ì ì„ í˜¸ ëª¨ë¸(${userSettings.preferred_model_id})ì„ ë“±ë¡ëœ ëª¨ë¸ê³¼ ë§¤ì¹­í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`)
      }

      // 4. ê¸°ë³¸ ëª¨ë¸ë“¤ ìš°ì„ ìˆœìœ„ (í™œì„±í™”ëœ ê²ƒë§Œ)
      const defaultModelPriority = ['claude-3-opus', 'claude-3-sonnet', 'gpt-4o', 'gpt-4-turbo', 'gemini-pro']

      for (const defaultModel of defaultModelPriority) {
        if (availableModelIds.has(defaultModel)) {
          console.log(`âœ… ê¸°ë³¸ ìš°ì„ ìˆœìœ„ ëª¨ë¸ ì„ íƒ: ${defaultModel}`)
          return defaultModel
        }
      }

      // 5. ë§ˆì§€ë§‰ìœ¼ë¡œ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸
      if (availableModelIds.size > 0) {
        const fallbackModel = Array.from(availableModelIds)[0]
        console.log(`âš ï¸ í´ë°± ëª¨ë¸ ì„ íƒ: ${fallbackModel}`)
        return fallbackModel
      }

      // 6. ì•„ë¬´ ëª¨ë¸ë„ ì—†ìœ¼ë©´ ì—ëŸ¬
      console.error('ğŸš¨ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤!')
      throw new Error('ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. AI Provider Factory ì´ˆê¸°í™”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')

    } catch (error) {
      console.warn('ğŸš¨ AI ëª¨ë¸ ì„ íƒ ì‹¤íŒ¨, í´ë°± ì‹œë„:', error)

      // ìµœí›„ì˜ í´ë°± - ë“±ë¡ëœ ì²« ë²ˆì§¸ ëª¨ë¸
      const availableModels = AIProviderFactory.getRegisteredModels()
      if (availableModels.length > 0) {
        const fallbackModel = availableModels[0].id
        console.log(`ğŸ†˜ ìµœí›„ í´ë°± ëª¨ë¸: ${fallbackModel}`)
        return fallbackModel
      }

      throw new Error('ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ì™€ AI Provider Factory ì´ˆê¸°í™”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')
    }
  }

  /**
   * AI ë¶„ì„ ì‹¤í–‰
   */
  private static async executeAIAnalysis(
    modelId: string,
    messages: AIMessage[],
    userId: string
  ): Promise<AIResponse> {
    try {
      console.log(`ğŸ¤– AI ë¶„ì„ ì‹œì‘:`, {
        modelId,
        userId,
        messageCount: messages.length,
        contentLength: messages.reduce((sum, msg) => sum + msg.content.length, 0)
      })

      // ë“±ë¡ëœ ëª¨ë¸ í™•ì¸
      const availableModels = AIProviderFactory.getRegisteredModels()
      console.log(`ğŸ“‹ ë“±ë¡ëœ AI ëª¨ë¸: ${availableModels.length}ê°œ`, availableModels.map(m => m.id))

      const selectedModel = AIProviderFactory.getModel(modelId)
      if (!selectedModel) {
        throw new Error(`AI ëª¨ë¸ '${modelId}'ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ${availableModels.map(m => m.id).join(', ')}`)
      }

      console.log(`âœ… ëª¨ë¸ í™•ì¸ë¨: ${selectedModel.name} (${selectedModel.provider})`)

      const response = await AIProviderFactory.generateCompletion(modelId, {
        messages,
        max_tokens: 4000,
        temperature: 0.3,
        user_id: userId
      })

      console.log(`âœ… AI ë¶„ì„ ì™„ë£Œ:`, {
        contentLength: response.content.length,
        cost: response.cost,
        inputTokens: response.usage.input_tokens,
        outputTokens: response.usage.output_tokens,
        responseTime: response.response_time
      })

      // API ì‚¬ìš©ëŸ‰ ê¸°ë¡
      await ApiUsageService.recordUsageBatch([{
        userId,
        model: modelId,
        inputTokens: response.usage.input_tokens,
        outputTokens: response.usage.output_tokens,
        cost: response.cost
      }])

      return response
    } catch (error) {
      console.error('ğŸš¨ AI ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨:', {
        modelId,
        userId,
        error: error instanceof Error ? error.message : String(error)
      })
      throw error
    }
  }

  /**
   * ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ íŒŒì‹±
   */
  private static parseDocumentAnalysisResult(aiResponse: string): any {
    try {
      console.log('ğŸ” AI ì‘ë‹µ íŒŒì‹± ì‹œì‘:', {
        responseLength: aiResponse.length,
        preview: aiResponse.substring(0, 200) + '...'
      })

      // JSON ë¸”ë¡ ì°¾ê¸° - ë” ì •í™•í•œ íŒ¨í„´ ì‚¬ìš©
      const jsonMatch = aiResponse.match(/\{(?:[^{}]|{[^{}]*})*\}/s)
      if (jsonMatch) {
        const parsedResult = JSON.parse(jsonMatch[0])
        console.log('âœ… JSON íŒŒì‹± ì„±ê³µ:', {
          hasKeyFields: !!(parsedResult.summary && parsedResult.keyInsights),
          resultKeys: Object.keys(parsedResult)
        })
        return parsedResult
      }

      // JSONì´ ì—†ìœ¼ë©´ ì‘ë‹µ ì „ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
      console.warn('âš ï¸ JSON í˜•ì‹ì´ ì•„ë‹Œ ì‘ë‹µ, í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬:', aiResponse.substring(0, 100))
      return {
        summary: aiResponse.substring(0, 500),
        keyInsights: ['AIê°€ JSON í˜•ì‹ì´ ì•„ë‹Œ ì‘ë‹µì„ ì œê³µí–ˆìŠµë‹ˆë‹¤.'],
        relevantWorkflowSteps: ['market_research', 'personas', 'proposal', 'budget'],
        extractedData: {},
        recommendations: ['ë¬¸ì„œ ë‚´ìš©ì„ ìˆ˜ë™ìœ¼ë¡œ ê²€í† í•´ì£¼ì„¸ìš”.'],
        confidence: 0.5
      }
    } catch (error) {
      console.error('âŒ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:', {
        error: error instanceof Error ? error.message : String(error),
        responsePreview: aiResponse.substring(0, 200)
      })
      return {
        summary: 'ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        keyInsights: ['AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨'],
        relevantWorkflowSteps: [],
        extractedData: {},
        recommendations: ['ìˆ˜ë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”.'],
        confidence: 0.1
      }
    }
  }

  /**
   * ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ ê²°ê³¼ íŒŒì‹±
   */
  private static parseWorkflowRecommendationsResult(aiResponse: string): any {
    try {
      console.log('ğŸ” ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ íŒŒì‹± ì‹œì‘:', {
        responseLength: aiResponse.length,
        preview: aiResponse.substring(0, 200) + '...'
      })

      // JSON ë¸”ë¡ ì°¾ê¸° - ë” ì •í™•í•œ íŒ¨í„´ ì‚¬ìš©
      const jsonMatch = aiResponse.match(/\{(?:[^{}]|{[^{}]*})*\}/s)
      if (jsonMatch) {
        const parsedResult = JSON.parse(jsonMatch[0])
        console.log('âœ… ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ JSON íŒŒì‹± ì„±ê³µ:', {
          hasOverallSummary: !!parsedResult.overallSummary,
          hasWorkflowRecommendations: !!parsedResult.workflowRecommendations,
          resultKeys: Object.keys(parsedResult)
        })
        return parsedResult
      }

      // JSONì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
      console.warn('âš ï¸ ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ JSON í˜•ì‹ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©')
      return {
        overallSummary: aiResponse.substring(0, 500),
        workflowRecommendations: {},
        nextSteps: ['ìˆ˜ë™ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”.']
      }
    } catch (error) {
      console.error('âŒ ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨:', {
        error: error instanceof Error ? error.message : String(error),
        responsePreview: aiResponse.substring(0, 200)
      })
      return {
        overallSummary: 'ì›Œí¬í”Œë¡œìš° ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
        workflowRecommendations: {},
        nextSteps: ['ìˆ˜ë™ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”.']
      }
    }
  }

  /**
   * ê¸°ì¡´ ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
   */
  private static async getExistingDocumentAnalysis(documentId: string): Promise<DocumentAnalysisResult | null> {
    try {
      const { data, error } = await supabase!
        .from('ai_analysis')
        .select('*')
        .eq('document_id', documentId)
        .eq('analysis_type', 'document_analysis')
        .eq('status', 'completed')
        .order('created_at', { ascending: false })
        .limit(1)

      if (error || !data || data.length === 0) return null

      const analysis = data[0]
      return JSON.parse(analysis.structured_data as string)

    } catch (error) {
      console.error('Failed to get existing document analysis:', error)
      return null
    }
  }

  /**
   * ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¡°íšŒ
   */
  private static async getWorkflowStatus(projectId: string): Promise<any> {
    try {
      // ê° ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ì™„ë£Œ ìƒíƒœ í™•ì¸
      const steps: WorkflowStep[] = ['market_research', 'personas', 'proposal', 'budget']
      const status: any = {}

      for (const step of steps) {
        const { data: analysis } = await supabase!
          .from('ai_analysis')
          .select('*')
          .eq('project_id', projectId)
          .eq('analysis_type', `${step}_analysis`)
          .eq('status', 'completed')
          .order('created_at', { ascending: false })
          .limit(1)

        status[step] = {
          completed: analysis && analysis.length > 0,
          lastAnalysis: analysis?.[0]?.created_at || null
        }
      }

      return status
    } catch (error) {
      console.error('Failed to get workflow status:', error)
      return {}
    }
  }

  /**
   * ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ì €ì¥
   */
  private static async saveDocumentAnalysisResult(
    result: DocumentAnalysisResult,
    modelId: string,
    aiResponse: AIResponse,
    userId: string
  ): Promise<void> {
    try {
      const model = AIProviderFactory.getModel(modelId)
      if (!model) throw new Error(`Model not found: ${modelId}`)

      await supabase!.from('ai_analysis').insert({
        document_id: result.documentId,
        analysis_type: 'document_analysis',
        workflow_step: null,
        workflow_type: 'proposal',
        ai_provider: model.provider,
        ai_model: modelId,
        prompt: JSON.stringify([]),
        response: aiResponse.content,
        structured_data: JSON.stringify(result),
        input_tokens: aiResponse.usage.input_tokens,
        output_tokens: aiResponse.usage.output_tokens,
        total_cost: aiResponse.cost,
        status: 'completed',
        processing_time: result.processingTime,
        created_by: userId,
        metadata: {
          documentAnalysis: true,
          fileName: result.fileName,
          confidence: result.confidence,
          timestamp: new Date().toISOString()
        }
      })

    } catch (error) {
      console.error('Failed to save document analysis result:', error)
      throw error
    }
  }

  /**
   * í†µí•© ë¶„ì„ ê²°ê³¼ ì €ì¥
   */
  private static async saveIntegratedAnalysisResult(
    result: IntegratedAnalysisResult,
    userId: string
  ): Promise<void> {
    try {
      await supabase!.from('ai_analysis').insert({
        project_id: result.projectId,
        analysis_type: 'integrated_document_analysis',
        workflow_step: 'document_analysis',
        workflow_type: 'proposal',
        ai_provider: 'multiple',
        ai_model: result.costSummary.modelUsed,
        prompt: JSON.stringify({}),
        response: JSON.stringify(result),
        structured_data: JSON.stringify(result.workflowRecommendations),
        input_tokens: result.costSummary.tokenUsage,
        output_tokens: 0,
        total_cost: result.costSummary.totalCost,
        status: 'completed',
        processing_time: result.totalProcessingTime,
        created_by: userId,
        metadata: {
          documentCount: result.documentInsights.length,
          integratedAnalysis: true,
          timestamp: new Date().toISOString()
        }
      })

    } catch (error) {
      console.error('Failed to save integrated analysis result:', error)
      throw error
    }
  }

  /**
   * í”„ë¡œì íŠ¸ì˜ ë¬¸ì„œ ë¶„ì„ ìƒíƒœ ì¡°íšŒ
   */
  static async getProjectAnalysisStatus(projectId: string): Promise<ProjectAnalysisStatus> {
    try {
      // ì „ì²´ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
      const { data: allDocs, error: allDocsError } = await supabase!
        .from('documents')
        .select('id')
        .eq('project_id', projectId)
        .eq('is_processed', true)

      if (allDocsError) throw allDocsError

      // ë¶„ì„ëœ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
      const { data: analyzedDocs, error: analyzedError } = await supabase!
        .from('ai_analysis')
        .select('document_id')
        .eq('analysis_type', 'document_analysis')
        .eq('status', 'completed')
        .in('document_id', allDocs?.map(d => d.id) || [])

      if (analyzedError) throw analyzedError

      // ìµœê·¼ í†µí•© ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
      const { data: recentAnalysis, error: recentError } = await supabase!
        .from('ai_analysis')
        .select('created_at, structured_data')
        .eq('project_id', projectId)
        .eq('workflow_step', 'document_analysis')
        .eq('analysis_type', 'integrated_document_analysis')
        .order('created_at', { ascending: false })
        .limit(1)

      if (recentError) throw recentError

      // ì›Œí¬í”Œë¡œìš° ì¤€ë¹„ë„ ê³„ì‚°
      const workflowReadiness: Record<WorkflowStep, number> = {
        market_research: 0,
        personas: 0,
        proposal: 0,
        budget: 0,
        document_analysis: 0
      }

      if (recentAnalysis && recentAnalysis.length > 0) {
        try {
          const structured = JSON.parse(recentAnalysis[0].structured_data as string)
          if (structured) {
            Object.keys(workflowReadiness).forEach(step => {
              if (structured[step]?.readiness) {
                workflowReadiness[step as WorkflowStep] = structured[step].readiness
              }
            })
          }
        } catch (error) {
          console.warn('Failed to parse structured data:', error)
        }
      }

      return {
        hasDocuments: (allDocs?.length || 0) > 0,
        documentsAnalyzed: analyzedDocs?.length || 0,
        totalDocuments: allDocs?.length || 0,
        lastAnalysis: recentAnalysis && recentAnalysis.length > 0 ? recentAnalysis[0].created_at : null,
        workflowReadiness
      }

    } catch (error) {
      console.error('Failed to get project analysis status:', error)
      throw error
    }
  }
}
